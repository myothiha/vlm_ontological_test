nohup: ignoring input
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|â–ˆâ–Ž        | 1/8 [00:02<00:14,  2.01s/it]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:03<00:11,  1.96s/it]Loading checkpoint shards:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:05<00:09,  1.97s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:07<00:07,  1.91s/it]Loading checkpoint shards:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:09<00:05,  1.77s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:09<00:02,  1.27s/it]Loading checkpoint shards:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:09<00:00,  1.06it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:09<00:00,  1.24s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Device set to use cuda:0
ðŸ”„ Generating Knowledge Questions for: person
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "person"

Ontological Knowledge:
[
  "The superclasses of person are [Agent, LivingThing].",
  "Person has object properties such as [hasChild, worksAt, owns].",
  "Person is composed of parts such as [head, body, limbs].",
  "Person has data properties such as [name, age, gender].",
  "Person can play roles such as [parent, employee, friend]."
]

Output: {

"yes_questions": [
    "Does the image contain an agent?",
    "Is there a living thing in the image that could own something?",
    "Is there an object in the image that has a head and body?",
    "Does the image contain something that could work at a place?",
    "Is there an object in the image that could be a parent?",
    "Does the image show someone who could have a name?",
    "Is there a living thing in the image that has age?",
    "Does the image contain an individual with gender?",
    "Is there an object in the image that could be an employee?",
    "Does the image show a person who could have children?"
],
  
"no_questions": [
    "Does the image contain a non-living thing?",
    "Is there an object in the image that is inanimate?",
    "Does the image show a living thing without a head?",
    "Is there an object in the image that doesn't have age?",
    "Does the image contain something that cannot own anything?",
    "Is there a living thing in the image that doesn't have a body?",
    "Does the image show someone who cannot have a name?",
    "Is there an object in the image that cannot work at a place?",
    "Does the image contain a living thing without limbs?",
    "Is there an object in the image that cannot be a parent?"
]
}

</think>

{
  "yes_questions": [
    "Does the image contain an agent?",
    "Is there a living thing in the image that could own something?",
    "Is there an object in the image that has a head and body?",
    "Does the image contain something that could work at a place?",
    "Is there an object in the image that could be a parent?",
    "Does the image show someone who could have a name?",
    "Is there a living thing in the image that has age?",
    "Does the image contain an individual with gender?",
    "Is there an object in the image that could be an employee?",
    "Does the image show a person who could have children?"
  ],
  "no_questions": [
    "Does the image contain a non-living thing?",
    "Is there an object in the image that is inanimate?",
    "Does the image show a living thing without a head?",
    "Is there an object in the image that doesn't have age?",
    "Does the image contain something that cannot own anything?",
    "Is there a living thing in the image that doesn't have a body?",
    "Does the image show someone who cannot have a name?",
    "Is there an object in the image that cannot work at a place?",
    "Does the image contain a living thing without limbs?",
    "Is there an object in the image that cannot be a parent?"
  ]
}
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: person
ðŸ”„ Generating Knowledge Questions for: bicycle
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "bicycle"

Ontological Knowledge:
[
  "What are the essential components that define a bicycle?",
  "How does a bicycle relate to its primary function of transportation?",
  "What are the types of bicycles based on their intended use?",
  "What are the structural parts that make up a bicycle frame?",
  "How is a bicycle typically powered?",
  "What are the common materials used in constructing a bicycle?",
  "What are the different types of wheels associated with a bicycle?",
  "What are the safety features commonly included in a bicycle?",
  "How does a bicycle interact with its environment during operation?",
  "What are the object properties that describe the relationship between a bicycle and its rider?"
]

Output: 

{
  "yes_questions": [
    "Is there an object in the image that has two wheels?",
    "Does the image contain something that is typically powered by human effort?",
    "Is there a vehicle in the image designed for transportation on land?",
    "Does the image show something that can be ridden by a person?",
    "Is there an object in the image made of materials like metal or carbon fiber?",
    "Does the image contain something with a frame that supports the rider?",
    "Is there a two-wheeled vehicle in the image meant for personal transport?",
    "Does the image show an object that includes safety features like brakes or lights?",
    "Is there something in the image that can be steered by handlebars?",
    "Does the image contain a vehicle that is commonly used for commuting or recreation?"
  ],
  
  "no_questions": [
    "Is there an object in the image that has four wheels?",
    "Does the image contain something that is typically powered by an internal combustion engine?",
    "Is there a vehicle in the image designed for water transportation?",
    "Does the image show something that is ridden standing up?",
    "Is there an object in the image made of materials like wood or plastic?",
    "Does the image contain something with a frame that is collapsible?",
    "Is there a four-wheeled vehicle in the image meant for personal transport?",
    "Does the image show an object that includes safety features like airbags?",
    "Is there something in the image that can be steered by a wheel and pedals?",
    "Does the image contain a vehicle that is commonly used for military purposes?"
  ]
}
</think>

{
  "yes_questions": [
    "Is there an object in the image that has two wheels?",
    "Does the image contain something that is typically powered by human effort?",
    "Is there a vehicle in the image designed for transportation on land?",
    "Does the image show something that can be ridden by a person?",
    "Is there an object in the image made of materials like metal or carbon fiber?",
    "Does the image contain something with a frame that supports the rider?",
    "Is there a two-wheeled vehicle in the image meant for personal transport?",
    "Does the image show an object that includes safety features like brakes or lights?",
    "Is there something in the image that can be steered by handlebars?",
    "Does the image contain a vehicle that is commonly used for commuting or recreation?"
  ],
  
  "no_questions": [
    "Is there an object in the image that has four wheels?",
    "Does the image contain something that is typically powered by an internal combustion engine?",
    "Is there a vehicle in the image designed for water transportation?",
    "Does the image show something that is ridden standing up?",
    "Is there an object in the image made of materials like wood or plastic?",
    "Does the image contain
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: bicycle
ðŸ”„ Generating Knowledge Questions for: car
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "car"

Ontological Knowledge:
[
  "What are the essential components that define a car?",
  "How does a car interact with its environment during operation?",
  "What are the primary functions performed by a car?",
  "What types of fuels or energy sources are typically used by a car?",
  "What are the key subsystems that contribute to the operation of a car?",
  "How does a car's design affect its performance and functionality?",
  "What are the common parts that are shared among different types of cars?",
  "How does a car's structure support its movement and stability?",
  "What are the different classes of cars based on their purpose or design?",
  "How do cars relate to other transportation systems in an ontology?"
]

Output: 
{
  "yes_questions": [
    "Is there an object in the image that is designed for transportation on land?",
    "Does the image contain a vehicle with wheels?",
    "Is there something in the image that typically uses fuel to operate?",
    "Does the image show an object that can carry passengers?",
    "Is there a vehicle in the image that is primarily used for personal transportation?"
  ],
  
  "no_questions": [
    "Does the image contain an aircraft?",
    "Is there a watercraft in the image?",
    "Does the image show a vehicle that operates without wheels?",
    "Is there an object in the image that is designed to fly?",
    "Does the image contain a vehicle that is powered by sails?"
  ]
}
</think>

{
  "yes_questions": [
    "Is there an object in the image that is designed for transportation on land?",
    "Does the image contain a vehicle with wheels?",
    "Is there something in the image that typically uses fuel to operate?",
    "Does the image show an object that can carry passengers?",
    "Is there a vehicle in the image that is primarily used for personal transportation?"
  ],
  
  "no_questions": [
    "Does the image contain an aircraft?",
    "Is there a watercraft in the image?",
    "Does the image show a vehicle that operates without wheels?",
    "Is there an object in the image that is designed to fly?",
    "Does the image contain a vehicle that is powered by sails?"
  ]
}
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: car
ðŸ”„ Generating Knowledge Questions for: motorcycle
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "motorcycle"

Ontological Knowledge:
[
  "List the superclasses of motorcycle.",
  "List the object properties where motorcycle appears as a subject.",
  "List the part-of relationships defined for motorcycle.",
  "List the data properties that describe motorcycle.",
  "List the subclasses of motorcycle.",
  "List the relationships motorcycle has with other classes."
]

Output: The JSON object as described.
</think>

{
  "yes_questions": [
    "Does the image contain a vehicle with two wheels?",
    "Is there an object in the image that could be ridden on roads?",
    "Does the image show something that typically has a fuel tank?",
    "Is there an object in the image that could have a handlebar and seat?",
    "Does the image contain a vehicle that might have a muffler?"
  ],
  "no_questions": [
    "Does the image contain a four-wheeled vehicle?",
    "Is there an object in the image that could carry multiple passengers?",
    "Does the image show something that typically has a trunk?",
    "Is there an object in the image that could be a boat?",
    "Does the image contain a vehicle that flies?"
  ]
}
</think>

```json
{
  "yes_questions": [
    "Does the image contain a vehicle with two wheels?",
    "Is there an object in the image that could be ridden on roads?",
    "Does the image show something that typically has a fuel tank?",
    "Is there an object in the image that could have a handlebar and seat?",
    "Does the image contain a vehicle that might have a muffler?"
  ],
  "no_questions": [
    "Does the image contain a four-wheeled vehicle?",
    "Is there an object in the image that could carry multiple passengers?",
    "Does the image show something that typically has a trunk?",
    "Is there an object in the image that could be a boat?",
    "Does the image contain a vehicle that flies?"
  ]
}
```
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: motorcycle
ðŸ”„ Generating Knowledge Questions for: airplane
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "airplane"

Ontological Knowledge:
[
  "What are the superclasses of airplane?",
  "What are the object properties where airplane appears as a subject?",
  "What are the part-of relationships defined for airplane?",
  "What are the data properties that describe airplane?",
  "What are the sub-classes of airplane?",
  "What are the related classes to airplane in the ontology?",
  "What are the functions of airplane?",
  "What are the design aspects of airplane?",
  "What are the safety features of airplane?",
  "What are the operational aspects of airplane?"
]

Output: {

}
</think>

{
  "yes_questions": [
    "Does the image contain a vehicle used for air travel?",
    "Is there an object in the image that has wings and a fuselage?",
    "Is there something in the image that could transport people or cargo?",
    "Does the image show an object that is designed to fly in the Earth's atmosphere?",
    "Is there an object in the image that could be equipped with engines for propulsion?"
  ],
  "no_questions": [
    "Does the image contain a watercraft used for sea travel?",
    "Is there an object in the image that has sails and a hull?",
    "Is there something in the image that could transport goods underground?",
    "Does the image show an object that is designed to move on land with wheels?",
    "Is there an object in the image that could be powered by wind?"
  ]
}
```json
{
  "yes_questions": [
    "Does the image contain a vehicle used for air travel?",
    "Is there an object in the image that has wings and a fuselage?",
    "Is there something in the image that could transport people or cargo?",
    "Does the image show an object that is designed to fly in the Earth's atmosphere?",
    "Is there an object in the image that could be equipped with engines for propulsion?"
  ],
  "no_questions": [
    "Does the image contain a watercraft used for sea travel?",
    "Is there an object in the image that has sails and a hull?",
    "Is there something in the image that could transport goods underground?",
    "Does the image show an object that is designed to move on land with wheels?",
    "Is there an object in the image that could be powered by wind?"
  ]
}
```
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: airplane
ðŸ”„ Generating Knowledge Questions for: bus
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "bus"

Ontological Knowledge:
[
  "The superclasses of bus are [Vehicle, TransportationDevice].",
  "Bus has object properties such as [hasRoute, carriesPassengers, operatedBy].",
  "Bus is composed of parts such as [engine, wheels, seats, doors].",
  "Bus has data properties such as [capacity, color, manufacturer, year]."
]

Output: 
{
  "yes_questions": [
    "Does the image contain a vehicle?",
    "Is there a transportation device in the image?",
    "Is there an object in the image that could carry passengers?",
    "Does the image show something that has a route?",
    "Is there an object in the image that has an engine and wheels?",
    "Is there a vehicle in the image that could be operated by a driver?",
    "Does the image contain something that could have seats and doors?",
    "Is there an object in the image that could transport people?",
    "Is there a transportation device in the image that has a manufacturer?",
    "Does the image show a vehicle that has a capacity limit?"
  ],
  
  "no_questions": [
    "Does the image contain a bird?",
    "Is there an object in the image that flies through the air?",
    "Does the image show a living creature?",
    "Is there something in the image that has wings?",
    "Does the image contain a vehicle that swims underwater?",
    "Is there an object in the image that can breathe oxygen?",
    "Does the image show a transportation device that is powered by wind?",
    "Is there a vehicle in the image that is smaller than a bicycle?",
    "Does the image contain a transportation device that has gills?",
    "Is there an object in the image that can photosynthesize?"
  ]
}
</think>

{
  "yes_questions": [
    "Does the image contain a vehicle?",
    "Is there a transportation device in the image?",
    "Is there an object in the image that could carry passengers?",
    "Does the image show something that has a route?",
    "Is there an object in the image that has an engine and wheels?",
    "Is there a vehicle in the image that could be operated by a driver?",
    "Does the image contain something that could have seats and doors?",
    "Is there an object in the image that could transport people?",
    "Is there a transportation device in the image that has a manufacturer?",
    "Does the image show a vehicle that has a capacity limit?"
  ],
  
  "no_questions": [
    "Does the image contain a bird?",
    "Is there an object in the image that flies through the air?",
    "Does the image show a living creature?",
    "Is there something in the image that has wings?",
    "Does the image contain a vehicle that swims underwater?",
    "Is there an object in the image that can breathe oxygen?",
    "Does the image show a transportation device that is powered by wind?",
    "Is there a vehicle in the image that is smaller than a bicycle?",
    "Does the image contain a transportation device that has gills?",
    "Is there an object in the image that can photosynthesize?"
  ]
}
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: bus
ðŸ”„ Generating Knowledge Questions for: train
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "train"

Ontological Knowledge:
[
  "The superclasses of train are [Vehicle, Locomotive].",
  "The object properties associated with train include [hasDriver, carriesPassengers, hasRoute].",
  "The part-of relationships for train involve [locomotive, passengerCar, cargoCar].",
  "The data properties describing train include [speed, length, weight].",
  "Entities related to train via object properties are [driver, passengers, route].",
  "The primary functions of train are [transporting passengers, carrying cargo, providing scheduled service]."
]

Output: JSON object
</think>

{
  "yes_questions": [
    "Does the image contain a vehicle that transports passengers?",
    "Is there an object in the image that could carry cargo?",
    "Is there a locomotive visible in the image?",
    "Does the image show something that has a driver?",
    "Is there an object in the image that provides scheduled service?"
  ],
  "no_questions": [
    "Does the image contain a car that flies?",
    "Is there an object in the image that swims underwater?",
    "Is there something in the image that lays eggs?",
    "Does the image show a bicycle used for carrying goods?",
    "Is there a boat in the image that moves on land?"
  ]
}
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: train
ðŸ”„ Generating Knowledge Questions for: truck
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "truck"

Ontological Knowledge:
[
  "The superclasses of truck are [Vehicle, Machinery].",
  "Truck has object properties such as [carriesLoad, transports, isOperatedBy].",
  "Truck is composed of parts such as [engine, wheels, chassis].",
  "Truck has data properties such as [loadCapacity, fuelType, weight]."
]

Output: {
  "yes_questions": [
    "Does the image contain a vehicle?",
    "Is there machinery in the image that could carry a load?",
    "Is there an object in the image that has an engine and wheels?",
    "Does the image show something that could be operated by a driver?",
    "Is there an object in the image that transports goods?"
  ],
  "no_questions": [
    "Does the image contain a bicycle?",
    "Is there an object in the image that is typically ridden by one person?",
    "Is there something in the image that flies through the air?",
    "Does the image show a watercraft?",
    "Is there an object in the image that has wings?"
  ]
}
</think>

{
  "yes_questions": [
    "Does the image contain a vehicle?",
    "Is there machinery in the image that could carry a load?",
    "Is there an object in the image that has an engine and wheels?",
    "Does the image show something that could be operated by a driver?",
    "Is there an object in the image that transports goods?"
  ],
  "no_questions": [
    "Does the image contain a bicycle?",
    "Is there an object in the image that is typically ridden by one person?",
    "Is there something in the image that flies through the air?",
    "Does the image show a watercraft?",
    "Is there an object in the image that has wings?"
  ]
}
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: truck
ðŸ”„ Generating Knowledge Questions for: boat
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "boat"

Ontological Knowledge:
[
  "The superclasses of Boat are [Vessel, Watercraft].",
  "The key functional components of a Boat include [engine, hull, mast, sails, navigation systems].",
  "Boat has object properties such as [hasPropulsion, hasNavigation, hasAnchoring].",
  "The primary materials used in constructing a Boat are [steel, fiberglass, aluminum, wood].",
  "Boat is composed of parts such as [hull, mast, sails, engine, rudder].",
  "The different types of propulsion systems used in Boats are [sail, motor, oar, paddle].",
  "Boat has data properties such as [length, width, draft, speed].",
  "The common uses or purposes of a Boat are [transportation, recreation, fishing, military].",
  "The environmental factors that influence the operation of a Boat are [weather conditions, water currents, tides].",
  "The safety features typically included in a Boat are [life jackets, fire extinguishers, emergency locator beacon]."
]

Output: {
  "yes_questions": [
    "Does the image contain a vessel?",
    "Is there an object in the image that could be used for transportation on water?",
    "Does the image show something that has a hull and an engine?",
    "Is there an object in the image that could be propelled by sails or a motor?",
    "Does the image contain a watercraft with navigation systems?",
    "Is there something in the image that could be made of steel or fiberglass?",
    "Does the image show an object that could be used for fishing or recreation?",
    "Is there an object in the image that could be influenced by weather conditions?",
    "Does the image contain something that has a mast and sails?",
    "Is there an object in the image that could include safety features like life jackets?"
  ],
  
  "no_questions": [
    "Does the image contain an aircraft?",
    "Is there an object in the image that could fly through the air?",
    "Does the image show something that has wings and an engine for flight?",
    "Is there an object in the image that could be used for space exploration?",
    "Does the image contain a land vehicle like a car or truck?",
    "Is there something in the image that could be made of feathers or fur?",
    "Does the image show an object that could be used for farming?",
    "Is there an object in the image that could be powered by solar energy?",
    "Does the image contain something that has a keyboard or monitor?",
    "Is there an object in the image that could be used for cooking food?"
  ]
}
</think>

{
  "yes_questions": [
    "Does the image contain a vessel?",
    "Is there an object in the image that could be used for transportation on water?",
    "Does the image show something that has a hull and an engine?",
    "Is there an object in the image that could be propelled by sails or a motor?",
    "Does the image contain a watercraft with navigation systems?",
    "Is there something in the image that could be made of steel or fiberglass?",
    "Does the image show an object that could be used for fishing or recreation?",
    "Is there an object in the image that could be influenced by weather conditions?",
    "Does the image contain something that has a mast and sails?",
    "Is there an object in the image that could include safety features like life jackets?"
  ],
  
  "no_questions": [
    "Does the image contain an aircraft?",
    "Is there an object in the image that could fly through the air?",
    "Does the image show something that has wings and an engine for flight?",
    "Is there an object in the image that could be used for space exploration?",
    "Does the image contain a land vehicle like a car or truck?",
    "Is there something in the image that could be made of feathers or fur?",
    "Does the image show
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: boat
ðŸ”„ Generating Knowledge Questions for: traffic light
LLM Response You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "traffic light"

Ontological Knowledge:
[
  "List the superclasses of traffic light.",
  "List the object properties where traffic light appears as a subject.",
  "List the part-of relationships defined for traffic light.",
  "List the data properties that describe traffic light.",
  "List the types of traffic light.",
  "List the relationships traffic light has with other entities.",
  "List the functions served by traffic light."
]

Output: The output should be in JSON format, with the two keys "yes_questions" and "no_questions", each containing an array of strings.
</think>

```json
{
  "yes_questions": [
    "Does the image contain a structure that regulates traffic flow?",
    "Is there an object in the image that provides visual signals to drivers?",
    "Does the image show something that can change colors to indicate different actions?",
    "Is there an object in the image that is typically found at intersections?",
    "Does the image contain something that helps prevent accidents by controlling traffic?"
  ],
  "no_questions": [
    "Does the image contain a pedestrian crossing sign?",
    "Is there an object in the image that provides audio signals?",
    "Does the image show something that is worn on a person's wrist?",
    "Is there an object in the image that is used for cooking?",
    "Does the image contain a vehicle that transports passengers?"
  ]
}
```
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: traffic light
ðŸ”„ Generating Knowledge Questions for: fire hydrant
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "fire hydrant"

Ontological Knowledge:
[
  "The superclasses of fire hydrant are [Public Safety Equipment, Outdoor Fixture].",
  "Fire hydrant has object properties such as [isInstalledIn, isMaintainedBy, isAccessibleFrom].",
  "Fire hydrant is composed of parts such as [valve, nozzle, standpipe].",
  "Fire hydrant has data properties such as [location, installationDate, pressureRating]."
]

Output: {
  "yes_questions": [
    "Does the image contain public safety equipment?",
    "Is there an outdoor fixture visible in the image?",
    "Is there an object in the image that could be maintained by a city worker?",
    "Does the image show something that could be accessible from the street?",
    "Is there a standpipe visible in the image?"
  ],
  "no_questions": [
    "Does the image contain a private safety item?",
    "Is there an indoor fixture visible in the image?",
    "Is there an object that could be maintained by a homeowner?",
    "Does the image show something that is not accessible from public areas?",
    "Is there a sink visible in the image?"
  ]
}
</think>

{
  "yes_questions": [
    "Does the image contain public safety equipment?",
    "Is there an outdoor fixture visible in the image?",
    "Is there an object in the image that could be maintained by a city worker?",
    "Does the image show something that could be accessible from the street?",
    "Is there a standpipe visible in the image?"
  ],
  "no_questions": [
    "Does the image contain a private safety item?",
    "Is there an indoor fixture visible in the image?",
    "Is there an object that could be maintained by a homeowner?",
    "Does the image show something that is not accessible from public areas?",
    "Is there a sink visible in the image?"
  ]
}
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: fire hydrant
ðŸ”„ Generating Knowledge Questions for: stop sign
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "stop sign"

Ontological Knowledge:
[
  "A stop sign is defined by its [octagonal shape, red color, and white text].",
  "A stop sign functions by [requiring drivers to come to a complete stop before proceeding].",
  "Typical dimensions of a stop sign include [30 inches in diameter], and it is usually made of [aluminum with a retro-reflective coating].",
  "The standard colors and symbols of a stop sign are [red background with white letters spelling 'STOP'].",
  "Stop signs are typically installed at [intersections, crossroads, and locations with high pedestrian traffic].",
  "Regulatory guidelines for stop sign placement include [visibility requirements, distance from the intersection, and placement above traffic lanes].",
  "Ignoring a stop sign can lead to [accidents, traffic violations, and potential legal consequences].",
  "A stop sign is related to other traffic control devices such as [yield signs, traffic lights, and crosswalk signals].",
  "A stop sign differs from other traffic signs by its [distinctive octagonal shape and bright red color].",
  "The data properties describing a stop sign include [shape, color, size, and placement requirements]."
]

Output: (as JSON)
Okay, so I need to generate yes/no questions for a stop sign based on the provided ontological knowledge. Let me start by understanding the knowledge given.

First, the stop sign is octagonal, red, and has white text. It's made of aluminum with a reflective coating. It's typically 30 inches in diameter and placed at intersections, crossroads, or areas with high pedestrian traffic. It requires drivers to stop completely. Ignoring it can lead to accidents or tickets. It's related to other traffic signs like yield signs and traffic lights, but it's distinct because of its shape and color.

Now, I need to create yes questions that would be true for a stop sign. These should be based on visual cues and the knowledge provided.

1. Does the image contain a red traffic control device? (Yes, because stop signs are red.)
2. Is there an object in the image that requires drivers to stop completely? (Yes, that's the function.)
3. Is there an octagonal-shaped object in the image? (Yes, the shape is distinctive.)
4. Does the image show a traffic sign with white letters spelling 'STOP'? (Yes, that's the standard.)
5. Is there a reflective object in the image meant to increase visibility? (Yes, made with reflective coating.)

For no questions, these should be statements that don't apply to a stop sign.

1. Does the image contain a green traffic light? (No, stop signs are red.)
2. Is there an object in the image that allows drivers to proceed without stopping? (No, stop signs require stopping.)
3. Is there a circular traffic sign in the image? (No, stop signs are octagonal.)
4. Does the image show a sign that gives directions to a location? (No, stop signs are regulatory, not informational.)
5. Is there an object in the image that is used to indicate a pedestrian crossing without requiring a stop? (No, that's a crosswalk signal, not a stop sign.)

I think these questions cover both the presence and absence of relevant features. Each question refers implicitly to the object in the image and uses both visual and ontological knowledge without mentioning'stop sign' directly.
</think>

```json
{
  "yes_questions": [
    "Does the image contain a red traffic control device?",
    "Is there an object in the image that requires drivers to stop completely?",
    "Is there an octagonal-shaped object in the image?",
    "Does the image show a traffic sign with white letters spelling 'STOP'?",
    "Is there a reflective object in the image meant to increase visibility?"
  ],
  "no_questions": [
    "Does the image contain a green traffic light?",
    "Is there an object in the image that allows drivers to proceed without stopping?",
    "Is there a circular traffic sign in the image?",
    "Does the image show a sign that gives directions to a
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: stop sign
ðŸ”„ Generating Knowledge Questions for: parking meter
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "parking meter"

Ontological Knowledge:
[
  "The superclasses of parking meter are [Public Facility, Urban Infrastructure].",
  "parking meter has object properties such as [isLocatedIn, isManagedBy, acceptsPayment].",
  "parking meter is composed of parts such as [display, payment slot, timer mechanism].",
  "parking meter has data properties such as [locationCoordinates, expirationTime, paymentAmount]."
]

Output: 
</think>

{
  "yes_questions": [
    "Does the image contain a public facility?",
    "Is there an urban infrastructure object in the image?",
    "Is there something in the image that accepts payment?",
    "Does the image show an object with a display and payment slot?",
    "Is there an object in the image that has a timer mechanism?"
  ],
  "no_questions": [
    "Does the image contain a residential building?",
    "Is there an object in the image that provides healthcare services?",
    "Is there something in the image that generates electricity?",
    "Does the image show a vehicle used for public transportation?",
    "Is there an object in the image that grows in a garden?"
  ]
}
</think>

```json
{
  "yes_questions": [
    "Does the image contain a public facility?",
    "Is there an urban infrastructure object in the image?",
    "Is there something in the image that accepts payment?",
    "Does the image show an object with a display and payment slot?",
    "Is there an object in the image that has a timer mechanism?"
  ],
  "no_questions": [
    "Does the image contain a residential building?",
    "Is there an object in the image that provides healthcare services?",
    "Is there something in the image that generates electricity?",
    "Does the image show a vehicle used for public transportation?",
    "Is there an object in the image that grows in a garden?"
  ]
}
```
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: parking meter
ðŸ”„ Generating Knowledge Questions for: bench
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "bench"

Ontological Knowledge:
[
  "Bench is part of [furniture].",
  "Bench is typically constructed using materials such as [wood, metal, concrete].",
  "The superclasses of bench are [furniture, object].",
  "Bench has object properties such as [locatedIn, madeOf, usedBy].",
  "Bench has data properties such as [length, width, weight, color].",
  "Bench is typically found in locations such as [park, garden, waiting area].",
  "Bench is used for purposes such as [seating, resting, decoration].",
  "Bench is related to other furniture types such as [chair, table, seating]."
]

Output: {
  "yes_questions": [
    "Does the image contain furniture?",
    "Is there an object in the image typically used for seating or resting?",
    "Is there something in the image made of wood or metal?",
    "Does the image show an object that is commonly found in a park or garden?",
    "Is there an object in the image that people might use to sit on?",
    "Does the image contain something that is related to chairs or tables?",
    "Is there a seating arrangement in the image?"
  ],
  
  "no_questions": [
    "Does the image contain a vehicle?",
    "Is there an object in the image typically used for cooking?",
    "Is there something in the image made of glass or plastic?",
    "Does the image show an object that is commonly found in a kitchen?",
    "Is there an object in the image that people might use to eat?",
    "Does the image contain something that is related to electronics?",
    "Is there a cooking appliance in the image?"
  ]
}
</think>

{
  "yes_questions": [
    "Does the image contain furniture?",
    "Is there an object in the image typically used for seating or resting?",
    "Is there something in the image made of wood or metal?",
    "Does the image show an object that is commonly found in a park or garden?",
    "Is there an object in the image that people might use to sit on?",
    "Does the image contain something that is related to chairs or tables?",
    "Is there a seating arrangement in the image?"
  ],
  
  "no_questions": [
    "Does the image contain a vehicle?",
    "Is there an object in the image typically used for cooking?",
    "Is there something in the image made of glass or plastic?",
    "Does the image show an object that is commonly found in a kitchen?",
    "Is there an object in the image that people might use to eat?",
    "Does the image contain something that is related to electronics?",
    "Is there a cooking appliance in the image?"
  ]
}
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: bench
ðŸ”„ Generating Knowledge Questions for: bird
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "bird"

Ontological Knowledge:
[
  "The superclasses of bird are [Organism, Vertebrate, Aves].",
  "Bird has object properties such as [livesIn, nestsIn, preysOn].",
  "Bird is composed of parts such as [feathers, wings, beak].",
  "Bird has data properties such as [species, wingspan, flightSpeed]."
]

Output: 
{
  "yes_questions": [
    "Does the image contain an organism?",
    "Is there a vertebrate in the image that might nest?",
    "Is there an object in the image that could have wings and a beak?",
    "Does the image contain something that could fly?",
    "Is there an object in the image that could be a prey to other animals?"
  ],
  
  "no_questions": [
    "Does the image contain a fish?",
    "Is there an object that could have fins instead of wings?",
    "Is there something in the image that lives in water exclusively?",
    "Is there a vehicle in the image that transports goods?",
    "Does the image show a cold-blooded organism?"
  ]
}
</think>

{
  "yes_questions": [
    "Does the image contain an organism?",
    "Is there a vertebrate in the image that might nest?",
    "Is there an object in the image that could have wings and a beak?",
    "Does the image contain something that could fly?",
    "Is there an object in the image that could be a prey to other animals?"
  ],
  
  "no_questions": [
    "Does the image contain a fish?",
    "Is there an object that could have fins instead of wings?",
    "Is there something in the image that lives in water exclusively?",
    "Is there a vehicle in the image that transports goods?",
    "Does the image show a cold-blooded organism?"
  ]
}
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: bird
ðŸ”„ Generating Knowledge Questions for: cat
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "cat"

Ontological Knowledge:
[
  "What are the primary characteristics that distinguish a cat from other Felidae species?",
  "How is the domestic cat related to wildcat species in terms of taxonomy?",
  "What are the essential parts of a cat's anatomy that contribute to its hunting behavior?",
  "What are the typical behaviors exhibited by cats that are essential for their survival?",
  "What are the common diseases that specifically affect domestic cats?",
  "How do cats interact with their environment in terms of habitat preferences?",
  "What are the typical life stages of a domestic cat from kitten to senior?",
  "What are the common breeds of domestic cats recognized by cat registries?",
  "What are the typical vocalizations made by cats and their purposes?",
  "What are the nutritional requirements specific to cats that differ from other mammals?"
]

Output: Please provide your JSON output here.

</think>

{
  "yes_questions": [
    "Does the image contain an animal that is a member of the Felidae family?",
    "Is there an object in the image that could have retractable claws?",
    "Is there a creature in the image that is known for its hunting behavior?",
    "Does the image show something that might have a tail used for balance?",
    "Is there an object in the image that could make purring sounds?"
  ],
  
  "no_questions": [
    "Does the image contain a dog?",
    "Is there an object that could have hooves instead of paws?",
    "Is there something in the image that is a herbivore?",
    "Is there a bird in the image that flies?",
    "Does the image show a creature that lays eggs?"
  ]
}
</think>

{
  "yes_questions": [
    "Does the image contain an animal that is a member of the Felidae family?",
    "Is there an object in the image that could have retractable claws?",
    "Is there a creature in the image that is known for its hunting behavior?",
    "Does the image show something that might have a tail used for balance?",
    "Is there an object in the image that could make purring sounds?"
  ],
  
  "no_questions": [
    "Does the image contain a dog?",
    "Is there an object that could have hooves instead of paws?",
    "Is there something in the image that is a herbivore?",
    "Is there a bird in the image that flies?",
    "Does the image show a creature that lays eggs?"
  ]
}
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: cat
ðŸ”„ Generating Knowledge Questions for: dog
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "dog"

Ontological Knowledge:
[
  "The immediate superclasses of Dog are [Canine, Mammal].",
  "Dog has object properties such as [hasOwner, barksAt, guards].",
  "The subclasses of Dog include [Labrador, German Shepherd, Poodle].",
  "Dog is composed of parts such as [tail, paws, ears].",
  "Dog has data properties such as [breed, age, weight].",
  "The functional roles associated with Dog include [guarding, herding, companionship]."
]

Output: {
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there a canine in the image?",
    "Does the image show an object that could guard something?",
    "Is there an animal in the image that might have a tail and paws?",
    "Is there something in the image that could be a companion?",
    "Does the image contain an animal that could bark?",
    "Is there an object in the image that could have ears and a tail?"
  ],
  "no_questions": [
    "Does the image contain a feline?",
    "Is there an object in the image that could lay eggs?",
    "Does the image show a reptile?",
    "Is there something in the image that could have scales instead of fur?",
    "Does the image contain a cold-blooded organism?",
    "Is there an animal in the image that could fly?",
    "Is there an object in the image that could produce milk without being a mammal?"
  ]
}
</think>

{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there a canine in the image?",
    "Does the image show an object that could guard something?",
    "Is there an animal in the image that might have a tail and paws?",
    "Is there something in the image that could be a companion?",
    "Does the image contain an animal that could bark?",
    "Is there an object in the image that could have ears and a tail?"
  ],
  "no_questions": [
    "Does the image contain a feline?",
    "Is there an object in the image that could lay eggs?",
    "Does the image show a reptile?",
    "Is there something in the image that could have scales instead of fur?",
    "Does the image contain a cold-blooded organism?",
    "Is there an animal in the image that could fly?",
    "Is there an object in the image that could produce milk without being a mammal?"
  ]
}
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: dog
ðŸ”„ Generating Knowledge Questions for: horse
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "horse"

Ontological Knowledge:
[
  "The superclasses of horse are [Animal, Mammal].",
  "Horse has object properties such as [hasOwner, gallops, grazes].",
  "Horse is composed of parts such as [mane, tail, hooves].",
  "Horse has data properties such as [coatColor, age, height]."
]

Output: Please provide the output as a JSON object.
</think>

```json
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might gallop?",
    "Is there an object in the image that could have a mane and hooves?",
    "Does the image contain something that could graze?",
    "Is there an object in the image that could be ridden?"
  ],
  
  "no_questions": [
    "Does the image contain a bird?",
    "Is there an object that could have wings?",
    "Is there something in the image that flies?",
    "Is there a vehicle in the image that has wheels?",
    "Does the image show a cold-blooded organism?"
  ]
}
```
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: horse
ðŸ”„ Generating Knowledge Questions for: sheep
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "sheep"

Ontological Knowledge:
[
  "The primary subclasses of sheep in biological taxonomy are [Ovis aries, domestic sheep, wild sheep].",
  "Sheep have object properties such as [grazesOn, matesWith, isHerdedBy].",
  "Sheep is composed of parts such as [wool, legs, horns].",
  "Sheep has data properties such as [coatColor, fleeceWeight, age]."
]

Output: [As per the instruction, provide the JSON output]
</think>

{
  "yes_questions": [
    "Does the image contain an animal that grazes on grass?",
    "Is there an object in the image that might be herded by humans?",
    "Does the image show something with wool or horns?",
    "Is there an animal in the image that could be part of a flock?",
    "Does the image contain an animal that typically has four legs?"
  ],
  
  "no_questions": [
    "Does the image contain a predator that hunts other animals?",
    "Is there an object in the image that could fly?",
    "Does the image show an animal that lives primarily in the ocean?",
    "Is there an object in the image that could be a domesticated pet?",
    "Does the image contain an animal that is known for its speed and agility in running?"
  ]
}
```json
{
  "yes_questions": [
    "Does the image contain an animal that grazes on grass?",
    "Is there an object in the image that might be herded by humans?",
    "Does the image show something with wool or horns?",
    "Is there an animal in the image that could be part of a flock?",
    "Does the image contain an animal that typically has four legs?"
  ],
  "no_questions": [
    "Does the image contain a predator that hunts other animals?",
    "Is there an object in the image that could fly?",
    "Does the image show an animal that lives primarily in the ocean?",
    "Is there an object in the image that could be a domesticated pet?",
    "Does the image contain an animal that is known for its speed and agility in running?"
  ]
}
```
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: sheep
ðŸ”„ Generating Knowledge Questions for: cow
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "cow"

Ontological Knowledge:
[
  "The superclasses of Cow are [Animal, Mammal].",
  "Cow has object properties such as [hasOwner, grazesOn, producesMilk].",
  "Cow is composed of parts such as [horns, tail, udder].",
  "Cow has data properties such as [weight, age, milkYield]."
]

Output: Please write a JSON object as per the instruction.
</think>

```json
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might graze on grass?",
    "Is there an object in the image that could have horns and an udder?",
    "Does the image contain something that could produce milk?",
    "Is there an object in the image that could be a farm animal?"
  ],
  "no_questions": [
    "Does the image contain a bird?",
    "Is there an object that could have wings instead of horns?",
    "Is there something in the image that lays eggs?",
    "Is there a vehicle in the image that flies?",
    "Does the image show a cold-blooded organism?"
  ]
}
```
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: cow
ðŸ”„ Generating Knowledge Questions for: elephant
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "elephant"

Ontological Knowledge:
[
  "What are the immediate superclasses of elephant?",
  "What are the specific types of elephants classified under the broader category of elephant?",
  "What are the key physical characteristics used to define an elephant?",
  "What are the ecological roles that elephants play in their habitats?",
  "What are the primary behaviors exhibited by elephants in their natural environment?",
  "What are the specific types of habitats where elephants are typically found?",
  "What are the main threats to the survival of elephants in their natural environment?",
  "What are the primary methods of communication used by elephants?",
  "What are the specific types of social structures observed in elephant populations?",
  "What are the main types of food sources that elephants consume in their natural habitat?"
]

Output: {
  "yes_questions": [
    "Does the image contain a large land mammal?",
    "Is there an animal in the image that has a trunk and tusks?",
    "Does the image show something that lives in African or Asian habitats?",
    "Is there an object in the image that could be part of a herd?",
    "Does the image contain something that communicates using low-frequency sounds?",
    "Is there an animal in the image that uses its trunk for drinking and eating?",
    "Does the image show an animal that is known to have a long lifespan?",
    "Is there an object in the image that could be a target for poaching?",
    "Does the image contain an animal that is a keystone species in its ecosystem?",
    "Is there something in the image that has thick, wrinkled skin?"
  ],
  "no_questions": [
    "Does the image contain a small rodent?",
    "Is there an object in the image that could be found in a freshwater aquarium?",
    "Does the image show something that flies?",
    "Is there an animal in the image that is typically kept as a household pet?",
    "Does the image contain a creature that has gills?",
    "Is there something in the image that could be found in a desert without water sources?",
    "Does the image show an animal that is cold-blooded?",
    "Is there an object in the image that could be used for transportation by humans?",
    "Does the image contain something that is primarily herbivorous but also carnivorous?",
    "Is there an animal in the image that is known for its speed in running?"
  ]
}
</think>

{
  "yes_questions": [
    "Does the image contain a large land mammal?",
    "Is there an animal in the image that has a trunk and tusks?",
    "Does the image show something that lives in African or Asian habitats?",
    "Is there an object in the image that could be part of a herd?",
    "Does the image contain something that communicates using low-frequency sounds?",
    "Is there an animal in the image that uses its trunk for drinking and eating?",
    "Does the image show an animal that is known to have a long lifespan?",
    "Is there an object in the image that could be a target for poaching?",
    "Does the image contain an animal that is a keystone species in its ecosystem?",
    "Is there something in the image that has thick, wrinkled skin?"
  ],
  "no_questions": [
    "Does the image contain a small rodent?",
    "Is there an object in the image that could be found in a freshwater aquarium?",
    "Does the image show something that flies?",
    "Is there an animal in the image that is typically kept as a household pet?",
    "Does the image contain a creature that has gills?",
    "Is there something in the image that could be found in a
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: elephant
ðŸ”„ Generating Knowledge Questions for: bear
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "bear"

Ontological Knowledge:
[
  "What are the key characteristics that distinguish a bear from other mammals?",
  "Which specific types of bears are recognized in the ontology?",
  "What are the primary habitats where bears are typically found?",
  "What are the common behaviors or activities associated with bears?",
  "What are the typical dietary preferences of bears?",
  "What are the main threats to the survival of bear species?",
  "What are the typical life cycle stages of a bear?",
  "What are the primary predators of bears in their natural habitats?",
  "What are the typical social structures or behaviors observed in bear populations?",
  "What are the main conservation efforts aimed at protecting bears?"
]

Output: 

{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that typically lives in forests or mountains?",
    "Is there an object in the image that could have a thick fur coat?",
    "Does the image show something that might hibernate during winter?",
    "Is there something in the image that could be a predator of smaller animals?"
  ],
  "no_questions": [
    "Does the image contain a bird?",
    "Is there an object that could be found in a desert habitat?",
    "Is there something in the image that could be an herbivorous animal?",
    "Does the image show a creature that lays eggs?",
    "Is there an object in the image that is typically found in urban areas?"
  ]
}
</think>

{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that typically lives in forests or mountains?",
    "Is there an object in the image that could have a thick fur coat?",
    "Does the image show something that might hibernate during winter?",
    "Is there something in the image that could be a predator of smaller animals?"
  ],
  "no_questions": [
    "Does the image contain a bird?",
    "Is there an object that could be found in a desert habitat?",
    "Is there something in the image that could be an herbivorous animal?",
    "Does the image show a creature that lays eggs?",
    "Is there an object in the image that is typically found in urban areas?"
  ]
}
```json
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that typically lives in forests or mountains?",
    "Is there an object in the image that could have a thick fur coat?",
    "Does the image show something that might hibernate during winter?",
    "Is there something in the image that could be a predator of smaller animals?"
  ],
  "no_questions": [
    "Does the image contain a bird?",
    "Is there an object that could be found in a desert habitat?",
    "Is there something in the image that could be an herbivorous animal?",
    "Does the image show a creature that lays eggs?",
    "Is there an object in the image that is typically found in urban areas?"
  ]
}
```
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: bear
ðŸ”„ Generating Knowledge Questions for: zebra
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "zebra"

Ontological Knowledge:
[
  "The superclasses of zebra are [Mammal, Herbivore, Equine].",
  "Zebras are distinguished by [black and white striped coats, unique stripe patterns, and robust build].",
  "Zebras are typically grouped in [herds, harems, and bachelor groups].",
  "Zebras are commonly found in [grasslands, savannahs, and open woodlands].",
  "Key behaviors exhibited by zebras include [group living, grazing, and sentinel behavior]."
]

Output: {
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that lives in herds?",
    "Does the image have something with a black and white striped coat?",
    "Is there an object in the image that grazes on grass?",
    "Does the image show something with a robust build?"
  ],
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object in the image that has scales instead of fur?",
    "Is there something in the image that lays eggs?",
    "Does the image show a solitary animal?",
    "Is there an object in the image that is a predator of large mammals?"
  ]
}
</think>

{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that lives in herds?",
    "Does the image have something with a black and white striped coat?",
    "Is there an object in the image that grazes on grass?",
    "Does the image show something with a robust build?"
  ],
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object in the image that has scales instead of fur?",
    "Is there something in the image that lays eggs?",
    "Does the image show a solitary animal?",
    "Is there an object in the image that is a predator of large mammals?"
  ]
}
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: zebra
ðŸ”„ Generating Knowledge Questions for: giraffe
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "giraffe"

Ontological Knowledge:
[
  "The superclasses of giraffe are [Animal, Mammal, Ruminant].",
  "Giraffe has object properties such as [hasHabitat, eats, livesIn].",
  "Giraffe is composed of parts such as [neck, legs, tail, spots].",
  "Giraffe has data properties such as [height, weight, lifespan, diet]."
]

Output: To solve this problem, I need to generate two sets of yes/no questions for a Vision-Language Model (VLM) based on the given ontological knowledge about a giraffe. The questions should be answerable using both visual cues and background knowledge, and they should refer to the object implicitly without using the class name directly.

First, I'll analyze the ontological knowledge provided:

1. Superclasses: Animal, Mammal, Ruminant.
2. Object properties: hasHabitat, eats, livesIn.
3. Parts: neck, legs, tail, spots.
4. Data properties: height, weight, lifespan, diet.

For the "yes_questions," I should create questions that would logically be answered "yes" if a giraffe is present. These questions should relate to the presence of features or behaviors associated with giraffes. For example, asking if the image contains a mammal would be a yes because giraffes are mammals.

For the "no_questions," I need to create questions that would not apply to a giraffe. These should relate to features or behaviors that are incompatible with giraffes. For instance, asking if the image contains a reptile would be a no because giraffes are mammals, not reptiles.

I'll ensure each question is phrased as a yes/no question and refers to the object implicitly. I'll avoid using the class name "giraffe" directly in the questions.

Now, I'll draft the questions based on these considerations.
</think>

```json
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that could have spots?",
    "Is there an object in the image that could have a long neck?",
    "Does the image contain something that could live in a savanna?",
    "Is there an object in the image that could be a ruminant?"
  ],
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}
```
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: giraffe
ðŸ”„ Generating Knowledge Questions for: backpack
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "backpack"

Ontological Knowledge:
[
  "What are the essential components that define a backpack?",
  "How does a backpack differ functionally from a briefcase?",
  "What are the typical materials used in constructing a backpack?",
  "Can a backpack be a part of another object, and if so, what are those objects?",
  "What are the common activities or contexts where a backpack is used?",
  "Are there any specific design patterns or styles commonly associated with backpacks?",
  "How does the size and capacity of a backpack influence its classification?",
  "What are the primary purposes or functions of a backpack?",
  "Are there any standard features that most backpacks share?",
  "How are backpacks typically categorized in terms of usage (e.g., school, travel)?"
]

Output: JSON
</think>

{
  "yes_questions": [
    "Is there an object in the image that could be used for carrying items on the back?",
    "Does the image contain something that is typically made of materials like fabric or nylon?",
    "Is there an object in the image that is commonly used during school or travel activities?",
    "Does the image show something that has compartments or straps for carrying?",
    "Is there an object in the image that is designed to be worn on the back for transporting belongings?"
  ],
  
  "no_questions": [
    "Does the image contain a briefcase or a similar document holder?",
    "Is there an object in the image that is primarily used for cooking or food preparation?",
    "Does the image show something that is typically worn on the feet?",
    "Is there an object in the image that is used for heating or cooling rooms?",
    "Does the image contain a vehicle part like a wheel or engine component?"
  ]
}
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: backpack
ðŸ”„ Generating Knowledge Questions for: umbrella
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "umbrella"

Ontological Knowledge:
[
  "The superclasses of umbrella are [Object, Tool].",
  "Umbrella is composed of parts such as [handle, canopy, ribs].",
  "Umbrella has object properties such as [isUsedFor, protectsFrom, isCarriedBy].",
  "Umbrella has data properties such as [color, size, materialType].",
  "The related classes describing materials used in umbrella are [Plastic, Metal, Fabric]."
]

Output: {
  "yes_questions": [
    "Does the image contain an object that can be used to protect from rain?",
    "Is there a tool in the image that is typically carried by people?",
    "Does the image show something that has a handle and a canopy?",
    "Is there an object in the image that could be made of fabric?",
    "Does the image contain a tool used to shield from the sun?"
  ],
  "no_questions": [
    "Does the image contain a tool used for cutting?",
    "Is there an object in the image that has a blade?",
    "Does the image show something that can be used to cook food?",
    "Is there a tool in the image that is used for writing?",
    "Does the image contain a tool that can be used to measure distances?"
  ]
}
</think>

{
  "yes_questions": [
    "Does the image contain an object that can be used to protect from rain?",
    "Is there a tool in the image that is typically carried by people?",
    "Does the image show something that has a handle and a canopy?",
    "Is there an object in the image that could be made of fabric?",
    "Does the image contain a tool used to shield from the sun?"
  ],
  "no_questions": [
    "Does the image contain a tool used for cutting?",
    "Is there an object in the image that has a blade?",
    "Does the image show something that can be used to cook food?",
    "Is there a tool in the image that is used for writing?",
    "Does the image contain a tool that can be used to measure distances?"
  ]
}
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: umbrella
ðŸ”„ Generating Knowledge Questions for: handbag
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "handbag"

Ontological Knowledge:
[
  "The superclasses of handbag are [Bag, Accessory].",
  "The subclasses of handbag include [Clutch, Tote, Shoulder Bag].",
  "A handbag consists of parts such as [Strap, Compartment, Closure].",
  "Handbag has object properties such as [hasBrand, isCarriedBy, contains].",
  "Handbag has data properties such as [color, size, material].",
  "Handbag is part of [Fashion Accessories, Personal Items].",
  "Materials typically used in handbag composition are [Leather, Fabric, Plastic].",
  "Functional relationships of handbag include [carrying items, providing storage, enhancing style]."
]

Output: {
  "yes_questions": [
    "Does the image contain a bag that is part of fashion accessories?",
    "Is there an accessory in the image that someone could carry?",
    "Does the image show something that has a strap and compartments?",
    "Is there an object in the image that could be used for carrying items?",
    "Does the image include a personal item that might have a closure?",
    "Is there something in the image that could enhance someone's style?",
    "Does the image contain a tote or shoulder bag?",
    "Is there an object in the image that could be made of leather or fabric?",
    "Is there an accessory in the image that someone could use to carry their belongings?",
    "Does the image show something that could be part of a person's personal items?"
  ],
  
  "no_questions": [
    "Does the image contain a vehicle that someone could drive?",
    "Is there an object in the image that could be used for cooking?",
    "Does the image show something that is typically found in a kitchen?",
    "Is there an electronic device in the image that can connect to the internet?",
    "Does the image contain a tool used for construction?",
    "Is there an object in the image that is used for medical purposes?",
    "Does the image show something that could be worn on the head?",
    "Is there a piece of furniture in the image that someone could sit on?",
    "Does the image contain a musical instrument?",
    "Is there an object in the image that is used for sports activities?"
  ]
}
</think>

{
  "yes_questions": [
    "Does the image contain a bag that is part of fashion accessories?",
    "Is there an accessory in the image that someone could carry?",
    "Does the image show something that has a strap and compartments?",
    "Is there an object in the image that could be used for carrying items?",
    "Does the image include a personal item that might have a closure?",
    "Is there something in the image that could enhance someone's style?",
    "Does the image contain a tote or shoulder bag?",
    "Is there an object in the image that could be made of leather or fabric?",
    "Is there an accessory in the image that someone could use to carry their belongings?",
    "Does the image show something that could be part of a person's personal items?"
  ],
  
  "no_questions": [
    "Does the image contain a vehicle that someone could drive?",
    "Is there an object in the image that could be used for cooking?",
    "Does the image show something that is typically found in a kitchen?",
    "Is there an electronic device in the image that can connect to the internet?",
    "Does the image contain a tool used for construction?",
    "Is there an object in the image that is used for medical purposes?",
    "Does the image show something that could be worn on the head?",

Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: handbag
ðŸ”„ Generating Knowledge Questions for: tie
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "tie"

Ontological Knowledge:
[
  "The different types of ties include [bow tie, necktie, cravat, ascot].",
  "Common materials for ties are [silk, polyester, wool, cotton].",
  "A tie is typically worn [around the neck, under a shirt collar, and tied in a knot].",
  "The components of a tie usually include [the blade, the tie band, the slip stitch, and the interlining].",
  "Common colors for ties are [solid colors like navy, red, blue, and patterns like stripes, checks, or geometric designs].",
  "Standard sizes for ties are [length around 57-63 cm and width around 8-10 cm].",
  "Different styles or patterns on ties include [solid, striped, checked, polka dot, and floral].",
  "Ties are commonly worn on [formal occasions, business meetings, weddings, and other events requiring attire].",
  "Accessories often paired with ties are [shirts, jackets, cufflinks, watches, and belts].",
  "Common manufacturing processes for ties include [cutting fabric, assembling components, stitching, and adding finishing touches like labels]."
]

Output: {
  "yes_questions": [
    "Does the image contain an object typically worn around the neck?",
    "Is there an item in the image that is usually paired with a shirt and jacket?",
    "Does the image show something that is commonly made from silk or polyester?",
    "Is there an object in the image that could be used in formal occasions?",
    "Does the image include an accessory that might have stripes or checks?",
    "Is there a necktie or similar item visible in the image?",
    "Does the image contain something that is usually worn under a shirt collar?",
    "Is there an object in the image that is typically tied in a knot?",
    "Does the image show an item that could be part of a business outfit?",
    "Is there a tie or similar neck accessory visible in the image?"
  ],
  "no_questions": [
    "Does the image contain a piece of clothing typically worn on the feet?",
    "Is there an object in the image that is used for cooking?",
    "Does the image show something that is usually worn around the waist?",
    "Is there an item in the image that is part of a bicycle?",
    "Does the image include an accessory that is typically worn on the head?",
    "Is there an object in the image that is used for cleaning?",
    "Does the image show something that is usually worn on the hands?",
    "Is there an item in the image that is part of a musical instrument?",
    "Does the image include an accessory that is typically worn on the ears?",
    "Is there an object in the image that is used for transportation?"
  ]
}

</think>

```json
{
  "yes_questions": [
    "Does the image contain an object typically worn around the neck?",
    "Is there an item in the image that is usually paired with a shirt and jacket?",
    "Does the image show something that is commonly made from silk or polyester?",
    "Is there an object in the image that could be used in formal occasions?",
    "Does the image include an accessory that might have stripes or checks?",
    "Is there a necktie or similar item visible in the image?",
    "Does the image contain something that is usually worn under a shirt collar?",
    "Is there an object in the image that is typically tied in a knot?",
    "Does the image show an item that could be part of a business outfit?",
    "Is there a tie or similar neck accessory visible in the image?"
  ],
  "no_questions": [
    "Does the image contain a piece of clothing typically worn on the feet?",
    "Is there an object in the image that is used for cooking?",
    "Does the image show something that is usually worn around the waist?",
    "Is there an item in the image that is part of a bicycle?",
    "Does the image include an accessory that is typically worn on the head?",
    "Is there an object
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: tie
ðŸ”„ Generating Knowledge Questions for: suitcase
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "suitcase"

Ontological Knowledge:
[
  "What are the primary materials used in the construction of a suitcase?",
  "What are the different types of compartments typically found in a suitcase?",
  "What object properties relate a suitcase to its contents?",
  "What data properties describe the dimensions of a suitcase?",
  "What are the common features that distinguish a suitcase from a briefcase?",
  "What are the part-of relationships that define the structure of a suitcase?",
  "What superclasses does the suitcase belong to in an ontology?",
  "What are the typical use cases or functions of a suitcase?",
  "What data properties are used to specify the weight capacity of a suitcase?",
  "What are the object properties that connect a suitcase to its manufacturer?"
]

Output: {
  "yes_questions": [
    "Does the image contain an object that is typically used for carrying personal belongings?",
    "Is there something in the image that could be used for traveling?",
    "Does the image show an object made from materials like plastic or fabric?",
    "Is there an object in the image that has compartments for organizing items?",
    "Does the image contain a portable container designed for holding clothes and accessories?"
  ],
  "no_questions": [
    "Does the image contain an object that is used for writing or drawing?",
    "Is there something in the image that could be worn on the head?",
    "Does the image show a tool used for cooking?",
    "Is there an object in the image that is a type of furniture?",
    "Does the image contain a device used for communication?"
  ]
}
</think>

```json
{
  "yes_questions": [
    "Does the image contain an object that is typically used for carrying personal belongings?",
    "Is there something in the image that could be used for traveling?",
    "Does the image show an object made from materials like plastic or fabric?",
    "Is there an object in the image that has compartments for organizing items?",
    "Does the image contain a portable container designed for holding clothes and accessories?"
  ],
  "no_questions": [
    "Does the image contain an object that is used for writing or drawing?",
    "Is there something in the image that could be worn on the head?",
    "Does the image show a tool used for cooking?",
    "Is there an object in the image that is a type of furniture?",
    "Does the image contain a device used for communication?"
  ]
}
```
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: suitcase
ðŸ”„ Generating Knowledge Questions for: frisbee
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "frisbee"

Ontological Knowledge:
[
  "The superclasses of Dog are [Animal, Mammal].",
  "Dog has object properties such as [hasOwner, barksAt, fetches].",
  "Dog is composed of parts such as [paws, tail, fur].",
  "Dog has data properties such as [age, weight, breed]."
]

Output: {
  "yes_questions": [
    "Does the image contain an animal?",
    "Is there a mammal in the image?",
    "Is there an object in the image that might fetch?",
    "Does the image contain something with paws?",
    "Is there an object in the image that could have a breed?"
  ],
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}
</think>

{
  "yes_questions": [
    "Does the image contain something that can be thrown?",
    "Is there an object in the image that could be used for a game?",
    "Does the image contain a disc-shaped object?",
    "Is there an object in the image that might be used outdoors?",
    "Is there something in the image that people often play with in a park?"
  ],
  "no_questions": [
    "Does the image contain a living creature?",
    "Is there an object in the image that could be a source of food?",
    "Does the image contain something that can fly?",
    "Is there an object in the image that could be used for cooking?",
    "Is there something in the image that can be worn as clothing?"
  ]
}
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: frisbee
ðŸ”„ Generating Knowledge Questions for: skis
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "skis"

Ontological Knowledge:
[
  "Skis are primarily constructed using materials such as [wood, metal, fiberglass, carbon fiber].",
  "The main components of skis include [base, core, top sheet, edges, bindings].",
  "Common bindings used with skis are [alpine bindings, telemark bindings, touring bindings].",
  "Skis are categorized into types such as [alpine skis, cross-country skis, telemark skis, snowboard skis].",
  "Standard dimensions for skis include [length, width, sidecut radius, camber].",
  "Common maintenance procedures for skis involve [waxing, edge sharpening, base repair, cleaning].",
  "Typical accessories for skis include [poles, boots, ski grips, ski bags].",
  "The environmental impacts of manufacturing skis include [resource extraction, energy consumption, waste generation].",
  "Performance metrics for evaluating skis include [speed, stability, maneuverability, durability].",
  "Common injuries associated with skiing, such as [ankle sprains, knee injuries, head injuries], can be influenced by ski design and usage."
]

Output: {
  "yes_questions": [
    "Does the image contain an object made primarily of wood, metal, fiberglass, or carbon fiber?",
    "Is there something in the image that includes components like a base, core, top sheet, edges, and bindings?",
    "Does the image show an object that could be used with alpine bindings, telemark bindings, or touring bindings?",
    "Is there an object in the image that is categorized as alpine skis, cross-country skis, telemark skis, or snowboard skis?",
    "Does the image contain something that has standard dimensions such as length, width, sidecut radius, or camber?",
    "Is there an object in the image that requires maintenance procedures like waxing, edge sharpening, base repair, or cleaning?",
    "Does the image show an object that is typically used with accessories such as poles, boots, ski grips, or ski bags?",
    "Is there something in the image that has performance metrics including speed, stability, maneuverability, or durability?",
    "Does the image contain an object that could contribute to environmental impacts like resource extraction, energy consumption, or waste generation?",
    "Is there an object in the image that might be associated with injuries such as ankle sprains, knee injuries, or head injuries?"
  ],
  "no_questions": [
    "Does the image contain an object made primarily of paper or plastic?",
    "Is there something in the image that includes components like a battery, screen, or speakers?",
    "Does the image show an object that could be used with smartphone bindings or camera mounts?",
    "Is there an object in the image that is categorized as a smartphone, tablet, or laptop?",
    "Does the image contain something that has standard dimensions such as screen size, battery capacity, or processor speed?",
    "Is there an object in the image that requires maintenance procedures like software updates, data backups, or virus scanning?",
    "Does the image show an object that is typically used with accessories such as chargers, earbuds, or adapters?",
    "Is there something in the image that has performance metrics including processing power, memory capacity, or storage speed?",
    "Does the image contain an object that could contribute to environmental impacts like e-waste, chemical leaching, or electronic pollution?",
    "Is there an object in the image that might be associated with injuries such as screen burns, repetitive strain, or electric shocks?"
  ]
}
</think>

```json
{
  "yes_questions": [
    "Does the image contain an object made primarily of wood, metal, fiberglass, or carbon fiber?",
    "Is there something in the image that includes components like a base, core, top sheet, edges, and bindings?",
    "Does the image show an object that could be used with alpine bindings, telemark bindings, or touring bindings?",
    "Is there an object in the image that is
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: skis
ðŸ”„ Generating Knowledge Questions for: snowboard
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "snowboard"

Ontological Knowledge:
[
  "The superclasses of snowboard are [Board, SportsEquipment].",
  "Snowboard has object properties such as [hasRider, hasBindings, hasSnowboardLength].",
  "Snowboard is composed of parts such as [base, edges, topsheet].",
  "Snowboard has data properties such as [length, width, flex]."
]

Output: To generate the ontological reasoning test questions for the class "snowboard," I will follow the provided instructions. 

First, I'll analyze the given ontological knowledge about snowboards. The superclasses are Board and SportsEquipment, which means any question about the presence of a sports equipment or a board-like object could be a yes question. The object properties include hasRider, hasBindings, hasSnowboardLength, which suggests that questions about something having a rider or bindings would be yes. The parts include base, edges, topsheet, so questions about these components could be yes. Data properties like length, width, flex imply questions about measurements or flexibility.

For yes_questions, I'll create questions that align with these aspects. For example, asking if there's a sports equipment, a board, something used for sliding on snow, something with bindings, etc.

For no_questions, I'll think of attributes or objects that are not related to snowboards. For instance, asking if it's a type of vehicle, a watercraft, something with wheels, something that requires fuel, etc.

I'll ensure each question is phrased as a yes/no question, refers implicitly to the object, and is grounded in either the presence or absence of ontological features without using the class name directly.

Finally, I'll structure the output as a JSON object with two arrays: yes_questions and no_questions, each containing the respective questions.
</think>

```json
{
  "yes_questions": [
    "Does the image contain sports equipment?",
    "Is there a board-like object in the image?",
    "Is there something in the image used for sliding on snow?",
    "Does the image show an object that could have bindings?",
    "Is there an object in the image that could have a rider?",
    "Is there something in the image that has a base and edges?",
    "Does the image contain something with a topsheet?",
    "Is there an object in the image that could be measured in length and width?"
  ],
  "no_questions": [
    "Does the image contain a vehicle?",
    "Is there a watercraft in the image?",
    "Does the image show something with wheels?",
    "Is there an object in the image that requires fuel?",
    "Does the image contain something that can be ridden on water?",
    "Is there an object in the image that is used for cooking?",
    "Does the image show something that can fly?",
    "Is there an object in the image that is used for farming?"
  ]
}
```
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: snowboard
ðŸ”„ Generating Knowledge Questions for: sports ball
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "sports ball"

Ontological Knowledge:
[
  "The primary materials used to construct a sports ball include [rubber, synthetic leather, plastic, bladder].",
  "The design of a sports ball influences its aerodynamic performance by affecting [air resistance, spin, trajectory].",
  "Different types of sports balls used in various sports include [soccer ball, basketball, tennis ball, volleyball].",
  "Object properties associated with a sports ball in an ontology include [isUsedIn, hasMaterial, hasDesign].",
  "Data properties that describe the characteristics of a sports ball include [size, weight, diameter, pressure].",
  "The part-of relationships that define the components of a sports ball include [outer cover, bladder, stitching].",
  "The superclasses of the sports ball class are [equipment, object].",
  "Functional relationships involving a sports ball in sports activities include [being kicked, being thrown, being hit]."
]

Output: {
  "yes_questions": [
    "Does the image contain an object that is used in sports activities?",
    "Is there an object in the image made of materials like rubber or synthetic leather?",
    "Is there something in the image that could be kicked or thrown?",
    "Does the image show an object that has stitching as part of its design?",
    "Is there an object in the image that is designed to affect aerodynamics through its shape?",
    "Does the image contain something that is part of the equipment used in a game?",
    "Is there an object in the image that has a bladder as part of its construction?",
    "Is there an object in the image that is typically used in a team sport?",
    "Does the image show an object that could be found on a sports field or court?",
    "Is there an object in the image that is designed to be hit with a racket or bat?"
  ],
  "no_questions": [
    "Does the image contain a piece of clothing?",
    "Is there an object in the image that is used for cooking?",
    "Does the image show something that is alive?",
    "Is there an object in the image that is part of a vehicle?",
    "Does the image contain a tool used for writing?",
    "Is there something in the image that is a type of furniture?",
    "Does the image show an object that is typically found in an office?",
    "Is there an object in the image that is used for measuring time?",
    "Does the image contain a musical instrument?",
    "Is there an object in the image that is a source of light?"
  ]
}
</think>

```json
{
  "yes_questions": [
    "Does the image contain an object that is used in sports activities?",
    "Is there an object in the image made of materials like rubber or synthetic leather?",
    "Is there something in the image that could be kicked or thrown?",
    "Does the image show an object that has stitching as part of its design?",
    "Is there an object in the image that is designed to affect aerodynamics through its shape?",
    "Does the image contain something that is part of the equipment used in a game?",
    "Is there an object in the image that has a bladder as part of its construction?",
    "Is there an object in the image that is typically used in a team sport?",
    "Does the image show an object that could be found on a sports field or court?",
    "Is there an object in the image that is designed to be hit with a racket or bat?"
  ],
  "no_questions": [
    "Does the image contain a piece of clothing?",
    "Is there an object in the image that is used for cooking?",
    "Does the image show something that is alive?",
    "Is there an object in the image that is part of a vehicle?",
    "Does the image contain a tool used for writing
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: sports ball
ðŸ”„ Generating Knowledge Questions for: kite
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "kite"

Ontological Knowledge:
[
  "What are the specific materials commonly used in the construction of a kite?",
  "How is a kite typically used in different cultural or recreational contexts?",
  "What are the primary components or parts that make up a kite?",
  "What are the object properties where kite appears as a subject in ontological relationships?",
  "What are the superclasses that the class \"kite\" belongs to in the ontology hierarchy?",
  "What are the part-of relationships defined for the class \"kite\" in the ontology?",
  "What are the data properties that describe the characteristics of a kite, such as size or shape?",
  "What are the relationships or interactions that a kite has with other classes, such as \"string\" or \"wind\"?"
]

Output: {
  "yes_questions": [
    "Does the image contain an object that is typically used in recreational activities?",
    "Is there something in the image that is made of specific materials like fabric or bamboo?",
    "Does the image show an object that has primary components such as a frame and a covering?",
    "Is there an object in the image that could interact with wind?",
    "Does the image contain a part that is often used in kite construction, like a string?"
  ],
  
  "no_questions": [
    "Does the image contain an object that is used for cooking?",
    "Is there something in the image that is made of metal for structural support?",
    "Does the image show an object that has an engine for propulsion?",
    "Is there an object in the image that could interact with water for transportation?",
    "Does the image contain a part that is used for electrical wiring?"
  ]
}

</think>

{
  "yes_questions": [
    "Does the image contain an object that is typically used in recreational activities?",
    "Is there something in the image that is made of specific materials like fabric or bamboo?",
    "Does the image show an object that has primary components such as a frame and a covering?",
    "Is there an object in the image that could interact with wind?",
    "Does the image contain a part that is often used in kite construction, like a string?"
  ],
  
  "no_questions": [
    "Does the image contain an object that is used for cooking?",
    "Is there something in the image that is made of metal for structural support?",
    "Does the image show an object that has an engine for propulsion?",
    "Is there an object in the image that could interact with water for transportation?",
    "Does the image contain a part that is used for electrical wiring?"
  ]
}
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: kite
ðŸ”„ Generating Knowledge Questions for: baseball bat
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "baseball bat"

Ontological Knowledge:
[
  "What are the physical dimensions typically associated with a baseball bat?",
  "What materials are commonly used in the construction of a baseball bat?",
  "What are the key components that make up a baseball bat?",
  "What are the functional properties that define a baseball bat?",
  "What are the constraints on the weight and length of a baseball bat in official games?",
  "What are the relationships between a baseball bat and other sports equipment?",
  "What are the different types or subclasses of baseball bats?",
  "What are the roles a baseball bat plays in the context of a baseball game?",
  "What are the data properties that quantify the performance of a baseball bat?",
  "What are the part-whole relationships involving a baseball bat?"
]

Output: Please provide the JSON output as per the instructions.
</think>

{
  "yes_questions": [
    "Does the image contain an object that is typically made of wood or metal?",
    "Is there something in the image that is used in a baseball game?",
    "Does the image show an object that is designed to hit a baseball?",
    "Is there an object in the image that is part of sports equipment?",
    "Does the image contain a tool used in a baseball field?"
  ],
  
  "no_questions": [
    "Does the image contain a ball used in baseball?",
    "Is there an object in the image that is worn on the feet?",
    "Does the image show a piece of clothing used in baseball?",
    "Is there an object in the image that is used for catching the ball?",
    "Does the image contain a helmet used in baseball?"
  ]
}
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: baseball bat
ðŸ”„ Generating Knowledge Questions for: baseball glove
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "baseball glove"

Ontological Knowledge:
[
  "The superclasses of baseball glove are [Glove, Protective Equipment].",
  "Baseball glove has object properties such as [isUsedIn, protectsHand].",
  "Baseball glove is composed of parts such as [leather, webbing, padding].",
  "Baseball glove has data properties such as [size, material, color]."
]

Output: {
  "yes_questions": [
    "Does the image contain protective equipment?",
    "Is there an object in the image that is used in baseball?",
    "Does the image show something that protects the hand?",
    "Is there a glove in the image made of leather and padding?",
    "Does the image contain an object that could be used to catch a ball?"
  ],
  
  "no_questions": [
    "Does the image contain a football helmet?",
    "Is there an object in the image that is used in soccer?",
    "Does the image show something that protects the head?",
    "Is there a glove in the image made of metal?",
    "Does the image contain an object that could be used to catch a puck?"
  ]
}
</think>

```json
{
  "yes_questions": [
    "Does the image contain protective equipment?",
    "Is there an object in the image that is used in baseball?",
    "Does the image show something that protects the hand?",
    "Is there a glove in the image made of leather and padding?",
    "Does the image contain an object that could be used to catch a ball?"
  ],
  "no_questions": [
    "Does the image contain a football helmet?",
    "Is there an object in the image that is used in soccer?",
    "Does the image show something that protects the head?",
    "Is there a glove in the image made of metal?",
    "Does the image contain an object that could be used to catch a puck?"
  ]
}
```
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: baseball glove
ðŸ”„ Generating Knowledge Questions for: skateboard
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "skateboard"

Ontological Knowledge:
[
  "The primary materials used in constructing a skateboard are [wood, metal, plastic].",
  "A skateboard is typically assembled by [attaching the trucks to the deck, placing the wheels on the trucks, and securing the components with bolts].",
  "The main functional parts of a skateboard are [deck, trucks, wheels, bearings].",
  "The activities or sports that commonly involve the use of a skateboard are [skateboarding, vert skating, street skating].",
  "A skateboard differs from other types of wheeled vehicles by [lacking a motor, having no seat, being designed for manual propulsion].",
  "The typical dimensions of a skateboard deck are [28 to 32 inches in length and 7 to 10 inches in width].",
  "The common types of skateboard wheels are [cruiser wheels, street wheels, downhill wheels].",
  "The design of a skateboard affects its performance by [influencing stability, speed, and maneuverability].",
  "The common modifications or customizations made to skateboards are [changing the grip tape, replacing the trucks, adding risers].",
  "The safety considerations when using a skateboard include [wearing protective gear, checking the board for damage, maintaining control at all times]."
]

Output: 
{
  "yes_questions": [
    "Is there an object in the image that could be used for manual propulsion?",
    "Does the image contain something that might have wheels?",
    "Is there an item in the image that could be used in a street skating activity?",
    "Does the image show an object that could be made from wood, metal, or plastic?",
    "Is there something in the image that has a deck and trucks as its main parts?",
    "Does the image contain an object that is typically used for vert skating?",
    "Is there an item in the image that could be customized with grip tape?",
    "Does the image show something that lacks a motor or seat?",
    "Is there an object in the image that could be designed for stability and maneuverability?",
    "Does the image contain something that might have bearings as part of its construction?"
  ],
  
  "no_questions": [
    "Is there a vehicle in the image that has a motor?",
    "Does the image show something that is designed to carry passengers?",
    "Is there an object that could be ridden without manual propulsion?",
    "Does the image contain something that is typically used in water sports?",
    "Is there an item in the image that is made from materials like rubber or canvas?",
    "Does the image show an object that has a seat or backrest?",
    "Is there something in the image that is designed for transporting goods?",
    "Does the image contain an object that is typically used for swimming?",
    "Is there an item in the image that is part of a bicycle?",
    "Does the image show something that is powered by an engine?"
  ]
}
</think>

{
  "yes_questions": [
    "Is there an object in the image that could be used for manual propulsion?",
    "Does the image contain something that might have wheels?",
    "Is there an item in the image that could be used in a street skating activity?",
    "Does the image show an object that could be made from wood, metal, or plastic?",
    "Is there something in the image that has a deck and trucks as its main parts?",
    "Does the image contain an object that is typically used for vert skating?",
    "Is there an item in the image that could be customized with grip tape?",
    "Does the image show something that lacks a motor or seat?",
    "Is there an object in the image that could be designed for stability and maneuverability?",
    "Does the image contain something that might have bearings as part of its construction?"
  ],
  
  "no_questions": [
    "Is there a vehicle in the image that has a motor?",
    "Does the image show something that is designed to carry passengers?",
    "Is there an object that could be ridden without manual propulsion?",
    "Does the image contain something that is typically used in water sports?",
    "Is there an item in the image that is made from
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: skateboard
ðŸ”„ Generating Knowledge Questions for: surfboard
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "surfboard"

Ontological Knowledge:
[
  "A surfboard is composed of parts such as [board, fins, leash, rails].",
  "Surfboards are constructed using materials such as [fiberglass, foam, epoxy resin, carbon fiber].",
  "A surfboard is designed for activities such as [surfing, wave riding, tow-in surfing].",
  "A surfboard's performance is defined by measurable properties such as [length, width, thickness, volume].",
  "The creation of a surfboard involves processes such as [shaping, glassing, sanding, finishing, adding hardware]."
]

Output: {
  "yes_questions": [
    "Is there an object in the image that is designed for activities like surfing?",
    "Does the image contain something made of materials like fiberglass or foam?",
    "Is there an object in the image that has parts such as fins and a leash?",
    "Does the image show something that could be ridden on waves?",
    "Is there a board-shaped object in the image that is used for water sports?"
  ],
  "no_questions": [
    "Is there an object in the image that is used for cooking?",
    "Does the image contain something that is typically found in a garden?",
    "Is there something in the image that is used for writing?",
    "Does the image show a vehicle that flies in the air?",
    "Is there an object in the image that is used for heating rooms?"
  ]
}
</think>

{
  "yes_questions": [
    "Is there an object in the image that is designed for activities like surfing?",
    "Does the image contain something made of materials like fiberglass or foam?",
    "Is there an object in the image that has parts such as fins and a leash?",
    "Does the image show something that could be ridden on waves?",
    "Is there a board-shaped object in the image that is used for water sports?"
  ],
  "no_questions": [
    "Is there an object in the image that is used for cooking?",
    "Does the image contain something that is typically found in a garden?",
    "Is there something in the image that is used for writing?",
    "Does the image show a vehicle that flies in the air?",
    "Is there an object in the image that is used for heating rooms?"
  ]
}
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: surfboard
ðŸ”„ Generating Knowledge Questions for: tennis racket
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "tennis racket"

Ontological Knowledge:
[
  "What are the primary materials used in the construction of a tennis racket?",
  "What are the different types of tennis rackets based on their frame design?",
  "What are the key components that make up a tennis racket?",
  "What are the object properties associated with a tennis racket in terms of its usage?",
  "What are the part-of relationships defined for a tennis racket?"
]

Output: {
  "yes_questions": [
    "Does the image contain something that could be used in a sport involving a ball?",
    "Is there an object in the image that is typically used to hit a ball over a net?",
    "Does the image show an object with a frame and strings for striking a ball?",
    "Is there something in the image that is used on a tennis court?",
    "Does the image contain an object designed for hitting a ball with an open face?"
  ],
  "no_questions": [
    "Does the image contain a ball used for playing tennis?",
    "Is there an object in the image that is used to catch a ball?",
    "Does the image show something that is worn on the feet?",
    "Is there an object in the image that is used to measure time?",
    "Does the image contain a piece of equipment used for cooking?"
  ]
}
</think>

{
  "yes_questions": [
    "Does the image contain something that could be used in a sport involving a ball?",
    "Is there an object in the image that is typically used to hit a ball over a net?",
    "Does the image show an object with a frame and strings for striking a ball?",
    "Is there something in the image that is used on a tennis court?",
    "Does the image contain an object designed for hitting a ball with an open face?"
  ],
  "no_questions": [
    "Does the image contain a ball used for playing tennis?",
    "Is there an object in the image that is used to catch a ball?",
    "Does the image show something that is worn on the feet?",
    "Is there an object in the image that is used to measure time?",
    "Does the image contain a piece of equipment used for cooking?"
  ]
}
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: tennis racket
ðŸ”„ Generating Knowledge Questions for: bottle
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "bottle"

Ontological Knowledge:
[
  "The superclasses of bottle are [Container, Vessel].",
  "Bottle has object properties such as [contains, madeOf, usedFor].",
  "Bottle is composed of parts such as [neck, body, base].",
  "Bottle has data properties such as [material, capacity, shape]."
]

Output: The JSON object with yes and no questions based on the given knowledge.
</think>

```json
{
  "yes_questions": [
    "Does the image contain a vessel that can hold liquid?",
    "Is there a container in the image that might have a neck and body?",
    "Is there an object in the image that could be made of glass or plastic?",
    "Does the image show something that could have a specific capacity?",
    "Is there an object in the image that is used for storing or transporting liquids?"
  ],
  "no_questions": [
    "Does the image contain a living organism?",
    "Is there an object in the image that could fly?",
    "Is there something in the image that is a source of light?",
    "Does the image show a vehicle used for transportation?",
    "Is there an object in the image that is a type of clothing?"
  ]
}
```
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: bottle
ðŸ”„ Generating Knowledge Questions for: wine glass
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "wine glass"

Ontological Knowledge:
[
  "A wine glass is commonly constructed using materials such as [glass, crystal, or borosilicate glass].",
  "The typical components of a wine glass include [stem, bowl, and base].",
  "The shape of a wine glass influences its function by affecting [the aroma, taste, and mouthfeel of the wine].",
  "The different types of wine glasses include [red wine, white wine, champagne, and dessert wine glasses].",
  "Object properties associated with a wine glass might include [holds, usedFor, pairedWith].",
  "Data properties describing a wine glass could include [capacity, material, shape, and height].",
  "The superclasses of a wine glass within an ontology are [vessel, container, and drinking utensil].",
  "A wine glass has relationships with entities such as [wine, drinking occasions, and users]."
]

Output: {
  "yes_questions": [
    "Does the image contain a vessel used for drinking?",
    "Is there a container in the image designed to hold liquid?",
    "Does the image show an object with a stem and bowl?",
    "Is there something in the image that could be paired with wine?",
    "Does the image contain a glass that affects the aroma of a drink?",
    "Is there an object in the image that is typically used during formal dining occasions?",
    "Does the image show a drinking utensil made of glass or crystal?"
  ],
  "no_questions": [
    "Does the image contain a vessel used for cooking?",
    "Is there a container in the image designed to hold food?",
    "Does the image show an object with a handle for cooking?",
    "Is there something in the image that could be used to cut food?",
    "Does the image contain a glass that is used for boiling water?",
    "Is there an object in the image that is typically used for serving ice cream?",
    "Does the image show a container made of metal or plastic?"
  ]
}
</think>

{
  "yes_questions": [
    "Does the image contain a vessel used for drinking?",
    "Is there a container in the image designed to hold liquid?",
    "Does the image show an object with a stem and bowl?",
    "Is there something in the image that could be paired with wine?",
    "Does the image contain a glass that affects the aroma of a drink?",
    "Is there an object in the image that is typically used during formal dining occasions?",
    "Does the image show a drinking utensil made of glass or crystal?"
  ],
  "no_questions": [
    "Does the image contain a vessel used for cooking?",
    "Is there a container in the image designed to hold food?",
    "Does the image show an object with a handle for cooking?",
    "Is there something in the image that could be used to cut food?",
    "Does the image contain a glass that is used for boiling water?",
    "Is there an object in the image that is typically used for serving ice cream?",
    "Does the image show a container made of metal or plastic?"
  ]
}
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: wine glass
ðŸ”„ Generating Knowledge Questions for: cup
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "cup"

Ontological Knowledge:
[
  "The superclasses of cup are [Container, Man-made object].",
  "The subclasses of cup are [Coffee cup, Tea cup, Mug, Ceremonial cup].",
  "Cup has object properties such as [contains, hasOwner, isUsedBy, isPartOfCollection].",
  "Cup is composed of parts such as [handle, base, body, lid].",
  "Cup has data properties such as [material, capacity, color, design]."
]

Output: {
  "yes_questions": [
    "Does the image contain a container?",
    "Is there a man-made object in the image?",
    "Is there an object in the image that could contain liquid?",
    "Does the image show something that might have a handle and a base?",
    "Is there an object in the image that could be part of a collection?",
    "Is there a cup-shaped object in the image?",
    "Does the image contain something that could be used to drink from?",
    "Is there an object in the image that might have a lid?",
    "Is there something in the image that could hold tea or coffee?",
    "Does the image show an object that could be made of ceramic?"
  ],
  
  "no_questions": [
    "Does the image contain a living organism?",
    "Is there an object in the image that could fly?",
    "Is there something in the image that grows in the ground?",
    "Does the image show a natural body of water?",
    "Is there a wild animal in the image?",
    "Does the image contain a vehicle?",
    "Is there an object in the image that could be used to transport people?",
    "Does the image show something that could be a source of light?",
    "Is there an object in the image that could be a living thing?",
    "Does the image contain something that could be alive?"
  ]
}
</think>

{
  "yes_questions": [
    "Does the image contain a container?",
    "Is there a man-made object in the image?",
    "Is there an object in the image that could contain liquid?",
    "Does the image show something that might have a handle and a base?",
    "Is there an object in the image that could be part of a collection?",
    "Is there a cup-shaped object in the image?",
    "Does the image contain something that could be used to drink from?",
    "Is there an object in the image that might have a lid?",
    "Is there something in the image that could hold tea or coffee?",
    "Does the image show an object that could be made of ceramic?"
  ],
  
  "no_questions": [
    "Does the image contain a living organism?",
    "Is there an object in the image that could fly?",
    "Is there something in the image that grows in the ground?",
    "Does the image show a natural body of water?",
    "Is there a wild animal in the image?",
    "Does the image contain a vehicle?",
    "Is there an object in the image that could be used to transport people?",
    "Does the image show something that could be a source of light?",
    "Is there an object in the image that could be a living thing?",
    "Does the image contain something that could be alive?"
  ]
}
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: cup
ðŸ”„ Generating Knowledge Questions for: fork
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "fork"

Ontological Knowledge:
[
  "What is the primary function of a fork?",
  "What are the essential components of a fork?",
  "How is a fork typically used in different cultural contexts?",
  "What materials are commonly used to make a fork?",
  "What are the common types of forks based on their usage?",
  "How does a fork relate to other dining utensils in a set?",
  "What are the different sizes of forks available?",
  "How is a fork different from a spoon or a knife?",
  "What is the purpose of the prongs on a fork?",
  "What is the typical shape of a fork's handle?"
]

Output: {
  "yes_questions": [
    "Does the image contain an object used for eating?",
    "Is there something in the image designed to hold food?",
    "Does the image show an object with prongs?",
    "Is there a utensil in the image typically used with a knife?",
    "Does the image include an object made of metal?",
    "Is there an object in the image used in a dining setting?",
    "Does the image have an object with multiple tines?",
    "Is there an object in the image that is part of a dinner set?",
    "Does the image contain an object that can be used to spear food?",
    "Is there a tool in the image meant for handling food during meals?"
  ],
  
  "no_questions": [
    "Does the image contain a spoon?",
    "Is there an object in the image designed to cut food?",
    "Does the image show a fork made of wood?",
    "Is there a utensil in the image used for drinking?",
    "Does the image include a tool meant for writing?",
    "Is there an object in the image that is a cooking pan?",
    "Does the image have an object used for transportation?",
    "Is there a piece of clothing in the image?",
    "Does the image contain a device used for communication?",
    "Is there an object in the image that is a musical instrument?"
  ]
}
</think>

{
  "yes_questions": [
    "Does the image contain an object used for eating?",
    "Is there something in the image designed to hold food?",
    "Does the image show an object with prongs?",
    "Is there a utensil in the image typically used with a knife?",
    "Does the image include an object made of metal?",
    "Is there an object in the image used in a dining setting?",
    "Does the image have an object with multiple tines?",
    "Is there an object in the image that is part of a dinner set?",
    "Does the image contain an object that can be used to spear food?",
    "Is there a tool in the image meant for handling food during meals?"
  ],
  
  "no_questions": [
    "Does the image contain a spoon?",
    "Is there an object in the image designed to cut food?",
    "Does the image show a fork made of wood?",
    "Is there a utensil in the image used for drinking?",
    "Does the image include a tool meant for writing?",
    "Is there an object in the image that is a cooking pan?",
    "Does the image have an object used for transportation?",
    "Is there a piece of clothing in the image?",
    "Does the image contain a device used for communication?",
    "Is there an object in the image that is a musical instrument?"
  ]
}
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: fork
ðŸ”„ Generating Knowledge Questions for: knife
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "knife"

Ontological Knowledge:
[
  "The superclasses of knife are [Tool, Utensil].",
  "Knife has object properties such as [hasBlade, hasHandle, isUsedForCutting].",
  "Knife is composed of parts such as [blade, handle, guard].",
  "Knife has data properties such as [length, material, sharpness]."
]

Output: {
  "yes_questions": [
    "Does the image contain a tool?",
    "Is there an object in the image that might be used for cutting?",
    "Is there an object in the image that could have a blade and handle?",
    "Does the image show something that is used for slicing?",
    "Is there a utensil in the image that could be sharp?"
  ],
  "no_questions": [
    "Does the image contain a spoon?",
    "Is there an object in the image that could be used for eating?",
    "Is there something in the image that could be used for cooking without cutting?",
    "Does the image show a tool that is typically used for measuring?",
    "Is there a utensil in the image that is used for stirring?"
  ]
}
</think>

{
  "yes_questions": [
    "Does the image contain a tool?",
    "Is there an object in the image that might be used for cutting?",
    "Is there an object in the image that could have a blade and handle?",
    "Does the image show something that is used for slicing?",
    "Is there a utensil in the image that could be sharp?"
  ],
  "no_questions": [
    "Does the image contain a spoon?",
    "Is there an object in the image that could be used for eating?",
    "Is there something in the image that could be used for cooking without cutting?",
    "Does the image show a tool that is typically used for measuring?",
    "Is there a utensil in the image that is used for stirring?"
  ]
}
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: knife
ðŸ”„ Generating Knowledge Questions for: spoon
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "spoon"

Ontological Knowledge:
[
  "The superclasses of Spoon are [Utensil, Object].",
  "Spoon is typically used for [eating, serving food].",
  "Spoon has data properties such as [material (metal, plastic, wood), shape (bowl, handle)].",
  "Spoon is composed of parts such as [bowl, handle, spoon rest].",
  "Spoon is commonly used in contexts such as [dining, cooking, decoration]."
]

Output: {
  "yes_questions": [
    "Does the image contain an object used for eating?",
    "Is there a utensil in the image?",
    "Does the image show something that can be made of metal or plastic?",
    "Is there an object in the image that has a bowl and a handle?",
    "Is there something in the image used in a dining setting?"
  ],
  "no_questions": [
    "Does the image contain a vehicle?",
    "Is there an object in the image that can fly?",
    "Does the image show something used for cooking food?",
    "Is there a living organism in the image?",
    "Is there an object in the image that can store electricity?"
  ]
}

</think>

{
  "yes_questions": [
    "Does the image contain an object used for eating?",
    "Is there a utensil in the image?",
    "Does the image show something that can be made of metal or plastic?",
    "Is there an object in the image that has a bowl and a handle?",
    "Is there something in the image used in a dining setting?"
  ],
  "no_questions": [
    "Does the image contain a vehicle?",
    "Is there an object in the image that can fly?",
    "Does the image show something used for cooking food?",
    "Is there a living organism in the image?",
    "Is there an object in the image that can store electricity?"
  ]
}
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: spoon
ðŸ”„ Generating Knowledge Questions for: bowl
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "bowl"

Ontological Knowledge:
[
  "What are the primary superclasses of a bowl?",
  "What object properties are associated with a bowl in an ontological model?",
  "Can a bowl be part of a larger system or structure, and if so, what are those relationships?",
  "What data properties are essential for defining a bowl?",
  "How is a bowl functionally related to other kitchen utensils?",
  "What are the key subclasses of a bowl within an ontology?",
  "What materials are commonly associated with the composition of a bowl?",
  "In what contexts or activities is a bowl typically used?"
]

Output: Please provide your output in the JSON format as per the example.
</think>

```json
{
  "yes_questions": [
    "Is there an object in the image that could hold liquids?",
    "Does the image contain something that is typically found in a kitchen?",
    "Is there an object in the image that might be used for serving food?",
    "Does the image show something that could be made of ceramic?",
    "Is there an object in the image that could be used for mixing ingredients?",
    "Does the image contain something that is often used with spoons?",
    "Is there an object in the image that could be part of a table setting?",
    "Does the image show something that could be used for eating cereal?",
    "Is there an object in the image that could be used in a microwave?",
    "Does the image contain something that could be used for cooking soup?"
  ],
  "no_questions": [
    "Does the image contain a vehicle?",
    "Is there an object in the image that could fly?",
    "Does the image show something that is typically found in a garden?",
    "Is there an object in the image that could be used for writing?",
    "Does the image contain something that could be worn as clothing?",
    "Is there an object in the image that could be used for transportation?",
    "Does the image show something that is typically found in a bathroom?",
    "Is there an object in the image that could be used for cooking meat?",
    "Does the image contain something that could be used for cleaning dishes?",
    "Is there an object in the image that could be used for storing money?"
  ]
}
```
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: bowl
ðŸ”„ Generating Knowledge Questions for: banana
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "banana"

Ontological Knowledge:
[
  "The different types of bananas include [ Cavendish, Plantain, Red Banana ].",
  "A banana is typically consumed [ raw, as a snack, in smoothies, or in baked goods ].",
  "The relationship between a banana and its peel is [ the peel protects the edible interior and is discarded before consumption ].",
  "The stages in the lifecycle of a banana are [ flowering, fruit development, ripening, and harvesting ].",
  "Common culinary uses of a banana include [ baking, blending into smoothies, adding to cereals, and making desserts ].",
  "A banana is defined as a fruit by [ its sweet taste, soft texture, and presence of seeds ].",
  "The parts of a banana cluster are [ individual bananas, the rachis, and the bracts ].",
  "A banana is related to the plant it grows on as [ it is the fruit of the banana plant, which is a type of herbaceous plant ].",
  "Different varieties of bananas include [ Cavendish, Plantain, Red Banana, and Goldfinger ].",
  "The typical lifecycle stages of a banana are [ flowering, fruit development, ripening, and harvesting ]."
]

Output: {
  "yes_questions": [
    "Is there a fruit in the image that is typically eaten raw or in smoothies?",
    "Does the image contain something that is commonly used in baking or desserts?",
    "Is there an object in the image that has a peel which is discarded before eating?",
    "Does the image show a fruit that is part of a cluster with other bananas?",
    "Is there something in the image that is a type of herbaceous plant's fruit?",
    "Does the image contain a fruit that is commonly found in tropical climates?",
    "Is there an object in the image that is sweet and has a soft texture?",
    "Does the image show something that is typically harvested after ripening?",
    "Is there a fruit in the image that is used in making smoothies or cereals?",
    "Does the image contain a fruit that is related to the Cavendish or Plantain varieties?"
  ],
  
  "no_questions": [
    "Does the image contain a vegetable?",
    "Is there an object in the image that is typically cooked before eating?",
    "Does the image show something that is a type of citrus fruit?",
    "Is there an object in the image that grows on a tree with woody stems?",
    "Does the image contain a fruit that is usually spicy or savory?",
    "Is there something in the image that is a type of berry?",
    "Does the image show a fruit that is typically used in savory dishes?",
    "Is there an object in the image that is a type of root vegetable?",
    "Does the image contain a fruit that is hard and crunchy?",
    "Is there something in the image that is a type of nut?"
  ]
}
</think>

{
  "yes_questions": [
    "Is there a fruit in the image that is typically eaten raw or in smoothies?",
    "Does the image contain something that is commonly used in baking or desserts?",
    "Is there an object in the image that has a peel which is discarded before eating?",
    "Does the image show a fruit that is part of a cluster with other bananas?",
    "Is there something in the image that is a type of herbaceous plant's fruit?",
    "Does the image contain a fruit that is commonly found in tropical climates?",
    "Is there an object in the image that is sweet and has a soft texture?",
    "Does the image show something that is typically harvested after ripening?",
    "Is there a fruit in the image that is used in making smoothies or cereals?",
    "Does the image contain a fruit that is related to the Cavendish or Plantain varieties?"
  ],
  "no_questions": [
    "Does the image contain a vegetable?",
    "Is there an object in the image that is typically cooked before eating?",
    "Does the image show something that is a type of citrus fruit?",
    "Is there an object in the image that grows
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: banana
ðŸ”„ Generating Knowledge Questions for: apple
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "apple"

Ontological Knowledge:
[
  "The superclasses of apple are [Fruit, Plant].",
  "Apple has object properties such as [hasVariety, growsOn, usedIn].",
  "Apple is composed of parts such as [core, skin, seeds].",
  "Apple has data properties such as [color, size, sweetnessLevel]."
]

Output: {
  "yes_questions": [
    "Does the image contain a fruit?",
    "Is there an object in the image that could grow on a tree?",
    "Is there something in the image that has a core and seeds?",
    "Does the image contain something that could be used in a pie?",
    "Is there an object in the image that might come in different varieties?"
  ],
  
  "no_questions": [
    "Does the image contain a vegetable?",
    "Is there an object in the image that could grow underground?",
    "Is there something in the image that has a peel instead of skin?",
    "Does the image contain a type of meat?",
    "Is there an object in the image that might be used in a sandwich as a protein source?"
  ]
}
</think>

```json
{
  "yes_questions": [
    "Does the image contain a fruit?",
    "Is there an object in the image that could grow on a tree?",
    "Is there something in the image that has a core and seeds?",
    "Does the image contain something that could be used in a pie?",
    "Is there an object in the image that might come in different varieties?"
  ],
  "no_questions": [
    "Does the image contain a vegetable?",
    "Is there an object in the image that could grow underground?",
    "Is there something in the image that has a peel instead of skin?",
    "Does the image contain a type of meat?",
    "Is there an object in the image that might be used in a sandwich as a protein source?"
  ]
}
```
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: apple
ðŸ”„ Generating Knowledge Questions for: sandwich
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "sandwich"

Ontological Knowledge:
[
  "The superclasses of sandwich are [Food, Meal].",
  "Sandwich has object properties such as [contains, isMadeOf, isServedWith].",
  "Sandwich is composed of parts such as [bread, filling, condiments].",
  "Sandwich has data properties such as [type, size, calorieContent]."
]

Output: {
  "yes_questions": [
    "Does the image contain a type of food?",
    "Is there something in the image that could be part of a meal?",
    "Is there an object in the image that includes bread?",
    "Does the image show something that could have a filling?",
    "Is there an object in the image that might be served with condiments?"
  ],
  
  "no_questions": [
    "Does the image contain a piece of clothing?",
    "Is there an object in the image that could be worn?",
    "Does the image show something that could be part of a vehicle?",
    "Is there something in the image that is a type of furniture?",
    "Is there an object in the image that could be used for cooking?"
  ]
}
</think>

```json
{
  "yes_questions": [
    "Does the image contain a type of food?",
    "Is there something in the image that could be part of a meal?",
    "Is there an object in the image that includes bread?",
    "Does the image show something that could have a filling?",
    "Is there an object in the image that might be served with condiments?"
  ],
  "no_questions": [
    "Does the image contain a piece of clothing?",
    "Is there an object in the image that could be worn?",
    "Does the image show something that could be part of a vehicle?",
    "Is there something in the image that is a type of furniture?",
    "Is there an object in the image that could be used for cooking?"
  ]
}
```
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: sandwich
ðŸ”„ Generating Knowledge Questions for: orange
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "orange"

Ontological Knowledge:
[
  "The taxonomic classifications of orange are [Citrus, Rutaceae, Sapindales, Magnoliopsida, Angiospermae, Plantae].",
  "An orange is defined as a fruit with [sweet, juicy flesh, thick rind, and numerous seeds].",
  "The typical growth stages of an orange are [seedling, sapling, flowering, fruit development, and ripening].",
  "Common culinary uses of orange include [juicing, zest in desserts, marmalade, and flavoring dishes].",
  "Nutritional properties of an orange include [high vitamin C, dietary fiber, and antioxidants].",
  "Orange is related to other citrus fruits such as [lemon, lime, grapefruit, and tangerine].",
  "Environmental factors affecting orange growth are [temperature, humidity, soil pH, and sunlight].",
  "Different varieties of orange include [Valencia, Navel, Blood, and Mandarin].",
  "Health benefits of consuming oranges are [boosting immunity, aiding digestion, and improving skin health].",
  "The parts of an orange are [peel, pith, pulp, juice, and seeds]."
]

Output: {
  "yes_questions": [
    "Does the image contain a fruit with sweet, juicy flesh?",
    "Is there an object in the image that is a type of citrus fruit?",
    "Does the image show something that could be used to make juice?",
    "Is there an object in the image that is a source of vitamin C?",
    "Does the image contain a fruit with a thick rind and numerous seeds?",
    "Is there something in the image that is related to lemon or lime?",
    "Does the image show a fruit that can be used for flavoring dishes?",
    "Is there an object in the image that is part of the Rutaceae family?",
    "Does the image contain a fruit that aids digestion?",
    "Does the image show a fruit with peel, pith, pulp, and seeds?"
  ],
  "no_questions": [
    "Does the image contain a fruit with sour flesh?",
    "Is there an object in the image that is a type of berry?",
    "Does the image show something that could be used to make jam instead of juice?",
    "Is there an object in the image that is a source of vitamin A?",
    "Does the image contain a fruit with a thin rind and few seeds?",
    "Is there something in the image that is related to apple or pear?",
    "Does the image show a fruit that can be used for making pies?",
    "Is there an object in the image that is part of the Rosaceae family?",
    "Does the image contain a fruit that causes constipation?",
    "Does the image show a fruit with only peel and pulp?"
  ]
}

</think>

{
  "yes_questions": [
    "Does the image contain a fruit with sweet, juicy flesh?",
    "Is there an object in the image that is a type of citrus fruit?",
    "Does the image show something that could be used to make juice?",
    "Is there an object in the image that is a source of vitamin C?",
    "Does the image contain a fruit with a thick rind and numerous seeds?",
    "Is there something in the image that is related to lemon or lime?",
    "Does the image show a fruit that can be used for flavoring dishes?",
    "Is there an object in the image that is part of the Rutaceae family?",
    "Does the image contain a fruit that aids digestion?",
    "Does the image show a fruit with peel, pith, pulp, and seeds?"
  ],
  "no_questions": [
    "Does the image contain a fruit with sour flesh?",
    "Is there an object in the image that is a type of berry?",
    "Does the image show something that could be used to make jam instead of juice?",
    "Is there an object in the image that is a source of vitamin A?",
    "Does the image contain a fruit with a thin rind and few seeds?",
   
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: orange
ðŸ”„ Generating Knowledge Questions for: broccoli
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "broccoli"

Ontological Knowledge:
[
  "The superclass of broccoli is [Vegetable].",
  "The subclasses of broccoli include [Calabrese, Romanesco].",
  "The parts of broccoli are [florets, stems, leaves].",
  "The typical use case of broccoli is [cooking, both raw and cooked].",
  "Broccoli belongs to the category of [cruciferous vegetables] in culinary contexts.",
  "The nutritional properties of broccoli include [fiber, vitamins C and K, potassium].",
  "The growth requirements for broccoli are [temperate climate, well-drained soil, moderate sunlight]."
]

Output: Please write the output in JSON format, without any markdown.
</think>

{
  "yes_questions": [
    "Does the image contain a vegetable?",
    "Is there an object in the image that could be used in cooking?",
    "Is there something in the image that has florets and stems?",
    "Does the image show a cruciferous vegetable?",
    "Is there an object in the image that provides vitamins C and K?"
  ],
  "no_questions": [
    "Does the image contain a fruit?",
    "Is there an object in the image that could be a source of carbohydrates?",
    "Is there something in the image that is typically found in desserts?",
    "Does the image show a vegetable that requires tropical climates to grow?",
    "Is there an object in the image that is classified as a root vegetable?"
  ]
}
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: broccoli
ðŸ”„ Generating Knowledge Questions for: carrot
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "carrot"

Ontological Knowledge:
[
  "What are the taxonomic classifications of carrot?",
  "What are the primary nutrients found in carrot?",
  "What are the common uses of carrot in cooking?",
  "What are the physical characteristics that define a carrot?",
  "What are the typical growing conditions for carrots?",
  "What are the relationships between carrot and other root vegetables?",
  "What are the parts of a carrot plant?",
  "What are the different varieties of carrot?",
  "What are the common pests that affect carrots?",
  "What are the health benefits associated with consuming carrots?"
]

Output: JSON
</think>

{
  "yes_questions": [
    "Does the image contain a root vegetable?",
    "Is there an object in the image that is typically orange in color?",
    "Does the image show something that is rich in beta-carotene?",
    "Is there an object that is commonly used in salads or stews?",
    "Does the image contain a vegetable that grows underground?",
    "Is there an object in the image that is crunchy and sweet?",
    "Does the image show something that is often paired with dip?",
    "Is there an object that is a source of vitamin A?",
    "Does the image contain a vegetable that is used in roasts or soups?",
    "Is there an object in the image that is a root crop?"
  ],
  
  "no_questions": [
    "Does the image contain a citrus fruit?",
    "Is there an object that is typically red in color?",
    "Does the image show something that is a type of berry?",
    "Is there an object that is commonly used in desserts?",
    "Does the image contain a vegetable that grows on a vine?",
    "Is there an object in the image that is soft and juicy?",
    "Does the image show something that is a type of leafy green?",
    "Is there an object that is a source of vitamin C?",
    "Does the image contain a vegetable that is used in sushi?",
    "Is there an object in the image that is a type of flower?"
  ]
}
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: carrot
ðŸ”„ Generating Knowledge Questions for: hot dog
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "hot dog"

Ontological Knowledge:
[
  "What are the primary ingredients typically found in a hot dog?",
  "How is a hot dog commonly prepared and served?",
  "What are the different types or variations of hot dogs across various cuisines?",
  "What are the common accompaniments or condiments served with a hot dog?",
  "What are the nutritional components typically associated with a hot dog?"
]

Output: The JSON object as described.
</think>

{
  "yes_questions": [
    "Does the image contain something that is typically made with processed meat?",
    "Is there an object in the image that is commonly served on a bun?",
    "Is there something in the image that might be accompanied by ketchup or mustard?",
    "Does the image show an item that is often grilled or cooked?",
    "Is there an object in the image that is a type of sausage?"
  ],
  "no_questions": [
    "Does the image contain a vegetable-based food item?",
    "Is there an object in the image that is typically raw or uncooked?",
    "Is there something in the image that is a type of fruit?",
    "Does the image show an item that is commonly served as a dessert?",
    "Is there an object in the image that is a type of fish or seafood?"
  ]
}
```json
{
  "yes_questions": [
    "Does the image contain something that is typically made with processed meat?",
    "Is there an object in the image that is commonly served on a bun?",
    "Is there something in the image that might be accompanied by ketchup or mustard?",
    "Does the image show an item that is often grilled or cooked?",
    "Is there an object in the image that is a type of sausage?"
  ],
  "no_questions": [
    "Does the image contain a vegetable-based food item?",
    "Is there an object in the image that is typically raw or uncooked?",
    "Is there something in the image that is a type of fruit?",
    "Does the image show an item that is commonly served as a dessert?",
    "Is there an object in the image that is a type of fish or seafood?"
  ]
}
```
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: hot dog
ðŸ”„ Generating Knowledge Questions for: pizza
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "pizza"

Ontological Knowledge:
[
  "What are the primary categories of pizza?",
  "What are the key components of pizza dough?",
  "What are the popular toppings that can be added to pizza?",
  "What are the distinct pizza dough recipes?",
  "What are the alternative terms or names for pizza?",
  "What are the various ways to cook pizza?",
  "What are the similar dishes or variations related to pizza?",
  "What are the typical serving recommendations for pizza?",
  "What are the nutritional elements found in pizza?",
  "What are the essential steps in making pizza?"
]

Output: {
  "yes_questions": [
    "Does the image show something that is typically served with cheese?",
    "Is there a dish in the image that is often made with dough?",
    "Does the image contain a food item that can be cooked in an oven?",
    "Is there something in the image that is usually cut into slices?",
    "Does the image include a food that people commonly eat with tomato sauce?"
  ],
  
  "no_questions": [
    "Does the image show a food that is typically served raw?",
    "Is there a dish in the image that is usually made with rice instead of dough?",
    "Does the image contain a food that is typically eaten without any sauce?",
    "Is there something in the image that is usually served in a bowl rather than on a plate?",
    "Does the image include a food that is typically low in carbohydrates?"
  ]
}

</think>

{
  "yes_questions": [
    "Does the image show something that is typically served with cheese?",
    "Is there a dish in the image that is often made with dough?",
    "Does the image contain a food item that can be cooked in an oven?",
    "Is there something in the image that is usually cut into slices?",
    "Does the image include a food that people commonly eat with tomato sauce?"
  ],
  
  "no_questions": [
    "Does the image show a food that is typically served raw?",
    "Is there a dish in the image that is usually made with rice instead of dough?",
    "Does the image contain a food that is typically eaten without any sauce?",
    "Is there something in the image that is usually served in a bowl rather than on a plate?",
    "Does the image include a food that is typically low in carbohydrates?"
  ]
}
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: pizza
ðŸ”„ Generating Knowledge Questions for: donut
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "donut"

Ontological Knowledge:
[
  "What are the superclasses of donut?",
  "What are the object properties where donut appears as a subject?",
  "What are the part-whole relationships defined for donut?",
  "What are the data properties that describe donut?",
  "What are the subclasses of donut?",
  "What are the attributes of donut?",
  "What are the relationships that donut has with other classes?"
]

Output: 

{
  "yes_questions": [
    "Is there a type of baked good in the image?",
    "Does the image contain something that is typically round in shape?",
    "Is there an object in the image that might be made with dough?",
    "Does the image show something that is often served as a dessert?",
    "Is there something in the image that is commonly topped with icing or sprinkles?"
  ],
  
  "no_questions": [
    "Does the image contain a vegetable?",
    "Is there an object in the image that is typically served as a main course?",
    "Does the image show something that is a type of fruit?",
    "Is there an object in the image that is usually rectangular in shape?",
    "Does the image contain something that is a type of clothing?"
  ]
}
</think>

{
  "yes_questions": [
    "Is there a type of baked good in the image?",
    "Does the image contain something that is typically round in shape?",
    "Is there an object in the image that might be made with dough?",
    "Does the image show something that is often served as a dessert?",
    "Is there something in the image that is commonly topped with icing or sprinkles?"
  ],
  
  "no_questions": [
    "Does the image contain a vegetable?",
    "Is there an object in the image that is typically served as a main course?",
    "Does the image show something that is a type of fruit?",
    "Is there an object in the image that is usually rectangular in shape?",
    "Does the image contain something that is a type of clothing?"
  ]
}
</think>

{
  "yes_questions": [
    "Is there a type of baked good in the image?",
    "Does the image contain something that is typically round in shape?",
    "Is there an object in the image that might be made with dough?",
    "Does the image show something that is often served as a dessert?",
    "Is there something in the image that is commonly topped with icing or sprinkles?"
  ],
  
  "no_questions": [
    "Does the image contain a vegetable?",
    "Is there an object in the image that is typically served as a main course?",
    "Does the image show something that is a type of fruit?",
    "Is there an object in the image that is usually rectangular in shape?",
    "Does the image contain something that is a type of clothing?"
  ]
}
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: donut
ðŸ”„ Generating Knowledge Questions for: cake
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "cake"

Ontological Knowledge:
[
  "The main components that make up a cake are [flour, sugar, eggs, butter, baking powder, milk].",
  "Subclasses of cake specific to certain cuisines include [cheesecake, red velvet cake, sponge cake].",
  "Object properties that define the relationship between a cake and its ingredients are [hasIngredient, madeFrom, composedOf].",
  "Data properties that specify the texture of a cake include [moistness, fluffiness, crumbStructure].",
  "Different types of cakes are related through subclasses such as [chocolate cake, fruit cake, layer cake].",
  "Part-whole relationships associated with a cake include [cakeLayer, frosting, filling].",
  "Data properties that describe the flavor of a cake are [sweetness, vanillaFlavor, chocolateFlavor].",
  "The superclasses that categorize a cake within the food domain are [Dessert, BakedGood].",
  "Object properties that link a cake to its method of preparation are [preparedUsing, bakedIn, decoratedWith].",
  "Data properties that indicate the intended use of a cake include [weddingCake, birthdayCake, teaCake]."
]

Output: {
  "yes_questions": [
    "Does the image contain a dessert?",
    "Is there a baked good in the image?",
    "Is there an object in the image that might have layers?",
    "Does the image show something that could be decorated with frosting?",
    "Is there something in the image that is sweet?",
    "Does the image contain an object that could be part of a wedding celebration?",
    "Is there an object in the image that might be made from flour and sugar?",
    "Does the image show something that is typically served during birthdays?",
    "Is there a cake layer visible in the image?",
    "Does the image contain something that could be a fruit cake?"
  ],
  
  "no_questions": [
    "Does the image contain a savory dish?",
    "Is there an object in the image that is a type of sandwich?",
    "Does the image show something that is typically served for breakfast?",
    "Is there an object in the image that is a type of soup?",
    "Does the image contain a main course meal?",
    "Is there something in the image that is made primarily of meat?",
    "Does the image show an object that is a type of vegetable?",
    "Is there an object in the image that is a type of drink?",
    "Does the image contain a dish that is typically spicy?",
    "Is there something in the image that is a type of bread?"
  ]
}

</think>

{
  "yes_questions": [
    "Does the image contain a dessert?",
    "Is there a baked good in the image?",
    "Is there an object in the image that might have layers?",
    "Does the image show something that could be decorated with frosting?",
    "Is there something in the image that is sweet?",
    "Does the image contain an object that could be part of a wedding celebration?",
    "Is there an object in the image that might be made from flour and sugar?",
    "Does the image show something that is typically served during birthdays?",
    "Is there a cake layer visible in the image?",
    "Does the image contain something that could be a fruit cake?"
  ],
  
  "no_questions": [
    "Does the image contain a savory dish?",
    "Is there an object in the image that is a type of sandwich?",
    "Does the image show something that is typically served for breakfast?",
    "Is there an object in the image that is a type of soup?",
    "Does the image contain a main course meal?",
    "Is there something in the image that is made primarily of meat?",
    "Does the image show an object that is a type of vegetable?",
    "Is there an object in the image that is a type of drink?",
    "Does the image contain a dish that is typically spicy?",
    "Is there something in the image that is a type of bread?"
  ]
}
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: cake
ðŸ”„ Generating Knowledge Questions for: chair
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "chair"

Ontological Knowledge:
[
  "The superclasses of chair are [Furniture, Seating].",
  "Chair has object properties such as [supports, isPartOf, hasMaterial].",
  "Chair is composed of parts such as [legs, seat, backrest].",
  "Chair has data properties such as [color, height, weight]."
]

Output: JSON object as described.
</think>

{
  "yes_questions": [
    "Does the image contain furniture that provides seating?",
    "Is there an object in the image designed to support someone sitting?",
    "Does the image show something with legs, a seat, and a backrest?",
    "Is there an object in the image that could be made of wood or metal?",
    "Does the image contain something that can be part of a room's seating arrangement?"
  ],
  
  "no_questions": [
    "Does the image contain a vehicle that can move people?",
    "Is there an object in the image that is a source of light?",
    "Does the image show something that can cook food?",
    "Is there an object in the image that is used for eating rather than sitting?",
    "Does the image contain a living organism?"
  ]
}
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: chair
ðŸ”„ Generating Knowledge Questions for: couch
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "couch"

Ontological Knowledge:
[
  "What materials are commonly used in the construction of a couch?",
  "What are the primary functions of a couch in a living space?",
  "What are the part-of relationships associated with a couch?",
  "What are the different types of couches (subclasses)?",
  "What object properties define the relationship between a couch and other furniture items?",
  "What data properties are typically used to describe a couch?"
]

Output: JSON
</think>

{
  "yes_questions": [
    "Does the image contain an object that is typically used for sitting or reclining?",
    "Is there a piece of furniture in the image that is often found in living rooms?",
    "Does the image show something that has parts like cushions and a frame?",
    "Is there an object in the image that can be a place to rest one's feet?",
    "Does the image contain a piece of furniture that can be made from materials like fabric or leather?"
  ],
  "no_questions": [
    "Is there an object in the image that is used primarily for cooking?",
    "Does the image contain a piece of furniture that is typically found in a bathroom?",
    "Is there something in the image that is used for cutting wood?",
    "Does the image show a vehicle used for transportation?",
    "Is there an object in the image that is a source of light?"
  ]
}
</think>

{
  "yes_questions": [
    "Does the image contain an object that is typically used for sitting or reclining?",
    "Is there a piece of furniture in the image that is often found in living rooms?",
    "Does the image show something that has parts like cushions and a frame?",
    "Is there an object in the image that can be a place to rest one's feet?",
    "Does the image contain a piece of furniture that can be made from materials like fabric or leather?"
  ],
  "no_questions": [
    "Is there an object in the image that is used primarily for cooking?",
    "Does the image contain a piece of furniture that is typically found in a bathroom?",
    "Is there something in the image that is used for cutting wood?",
    "Does the image show a vehicle used for transportation?",
    "Is there an object in the image that is a source of light?"
  ]
}
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: couch
ðŸ”„ Generating Knowledge Questions for: potted plant
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "potted plant"

Ontological Knowledge:
[
  "A potted plant consists of essential components such as [soil, plant, pot].",
  "The primary function of a potted plant is [to provide aesthetic value and improve indoor air quality].",
  "Common materials for constructing the pot of a potted plant include [ceramic, plastic, terracotta].",
  "Typical containers for a potted plant are [flower pots, hanging baskets, planters].",
  "The life cycle stages of a potted plant include [germination, growth, flowering, senescence]."
]

Output: {
  "yes_questions": [
    "Does the image contain something that improves indoor air quality?",
    "Is there an object in the image that has soil, a plant, and a pot?",
    "Is there a flower pot in the image that could be made of ceramic?",
    "Does the image show something that goes through germination and growth stages?",
    "Is there an object in the image that provides aesthetic value?"
  ],
  "no_questions": [
    "Does the image contain a vehicle used for transportation?",
    "Is there an object in the image that is a source of electrical power?",
    "Does the image show something that can be used to cook food?",
    "Is there a musical instrument in the image?",
    "Does the image contain a piece of clothing?"
  ]
}
</think>

{
  "yes_questions": [
    "Does the image contain something that improves indoor air quality?",
    "Is there an object in the image that has soil, a plant, and a pot?",
    "Is there a flower pot in the image that could be made of ceramic?",
    "Does the image show something that goes through germination and growth stages?",
    "Is there an object in the image that provides aesthetic value?"
  ],
  "no_questions": [
    "Does the image contain a vehicle used for transportation?",
    "Is there an object in the image that is a source of electrical power?",
    "Does the image show something that can be used to cook food?",
    "Is there a musical instrument in the image?",
    "Does the image contain a piece of clothing?"
  ]
}
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: potted plant
ðŸ”„ Generating Knowledge Questions for: bed
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "bed"

Ontological Knowledge:
[
  "The different types of beds based on their structure include [mattress, frame, headboard, footboard].",
  "Commonly used materials for constructing beds are [wood, metal, plastic, fabric].",
  "The standard dimensions of a bed vary, but common sizes are [twin, full, queen, king].",
  "Essential components for a bed's functionality are [mattress support, frame stability, sleeping surface].",
  "A bed is related to other furniture items in a bedroom such as [nightstands, dressers, mirrors, wardrobes].",
  "Common uses of a bed in different cultural contexts include [sleeping, resting, sitting, lounging].",
  "Possible configurations of bed frames include [platform, canopy, four-poster, low-profile].",
  "Typical accessories associated with beds are [sheets, pillows, blankets, bedspreads].",
  "Beds differ in intended use, such as [sleeping, reading, resting, lounging].",
  "Safety standards applicable to bed designs include [structural integrity, fire resistance, material safety]."
]

Output: JSON
</think>

{
  "yes_questions": [
    "Is there an object in the image that is typically used for sleeping?",
    "Does the image contain a piece of furniture with a mattress and frame?",
    "Is there something in the image that could be used for resting or lounging?",
    "Does the image show a structure that might have a headboard or footboard?",
    "Is there an object in the image that is commonly found in a bedroom with nightstands or dressers?"
  ],
  "no_questions": [
    "Does the image contain a piece of furniture used for cooking?",
    "Is there an object in the image that is typically found in a bathroom?",
    "Does the image show a vehicle used for transportation?",
    "Is there something in the image that is used for storing food?",
    "Does the image contain a tool used for gardening?"
  ]
}
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: bed
ðŸ”„ Generating Knowledge Questions for: dining table
LLM Response Instruction:
You are an AI assistant designed to generate **ontological reasoning test questions** for a Vision-Language Model (VLM). You will be given the name of an object class and a list of ontological knowledge statements about it.

Assume the input is an image that may contain multiple objects, including an instance of the given class.

Your task is to create two sets of yes/no questions:
- Questions where the correct answer would be **"yes"** based on the provided knowledge
- Questions where the correct answer would be **"no"** because the statement would not apply to the given object according to its ontology

Each question must:
- Be answerable using both **visual cues** and **background ontological knowledge**
- Be phrased as a **yes/no** question
- Refer to the object **implicitly** (e.g., "an object", "something in the image")
- Be grounded either in the **presence** or **absence** of ontological features
- Avoid using the objectâ€™s class name directly in the question

Return your output as a JSON object with two keys: `"yes_questions"` and `"no_questions"`.
Each key should contain a JSON array of strings (questions).

Do not include any explanations.

--- Start of examples ---

Example for Cat:

Ontological Knowledge:
[
  "The superclasses of Cat are [Animal, Mammal].",
  "Cat has object properties such as [hasOwner, hunts, livesWith].",
  "Cat is composed of parts such as [whiskers, tail, paws].",
  "Cat has data properties such as [furColor, age, weight]."
]

Output:
{
  "yes_questions": [
    "Does the image contain a mammal?",
    "Is there an animal in the image that might live with humans?",
    "Is there an object in the image that could have whiskers and paws?",
    "Does the image contain something that could hunt?",
    "Is there an object in the image that could be a pet?"
  ],
  
  "no_questions": [
    "Does the image contain a reptile?",
    "Is there an object that could have scales instead of fur?",
    "Is there something in the image that lays eggs underwater?",
    "Is there a vehicle in the image that transports people?",
    "Does the image show a cold-blooded organism?"
  ]
}

--- End of examples ---

Now generate ontological test questions for:

Class: "dining table"

Ontological Knowledge:
[
  "The primary materials used in constructing a dining table are [wood, metal, glass, stone, plastic].",
  "A dining table differs from other tables by being specifically designed for [serving meals, seating multiple people, providing a communal eating space].",
  "Common dimensions of a standard dining table are [72 inches length, 36 inches width, 28-30 inches height].",
  "The typical components of a dining table include [tabletop, legs, sometimes a center support, and possibly leaves or extensions].",
  "Various styles of dining tables include [rectangular, round, oval, square, extendable, drop-leaf, and pub-style]."
]

Output: {
  "yes_questions": [
    "Is there a piece of furniture in the image designed for serving meals?",
    "Does the image contain a table that is intended for seating multiple people?",
    "Is there an object in the image that provides a communal eating space?",
    "Does the image show a table made of materials such as wood, metal, glass, stone, or plastic?",
    "Is there a table in the image that has a standard height between 28-30 inches?"
  ],
  
  "no_questions": [
    "Is there a table in the image designed for serving meals that is not made of wood, metal, glass, stone, or plastic?",
    "Does the image contain a table that is specifically intended for seating only one person?",
    "Is there an object in the image that is a dining table without any legs?",
    "Does the image show a dining table with a height outside the typical range of 28-30 inches?",
    "Is there a dining table in the image that is not designed for serving meals or seating multiple people?"
  ]
}
</think>

```json
{
  "yes_questions": [
    "Is there a piece of furniture in the image designed for serving meals?",
    "Does the image contain a table that is intended for seating multiple people?",
    "Is there an object in the image that provides a communal eating space?",
    "Does the image show a table made of materials such as wood, metal, glass, stone, or plastic?",
    "Is there a table in the image that has a standard height between 28-30 inches?"
  ],
  "no_questions": [
    "Is there a table in the image designed for serving meals that is not made of wood, metal, glass, stone, or plastic?",
    "Does the image contain a table that is specifically intended for seating only one person?",
    "Is there an object in the image that is a dining table without any legs?",
    "Does the image show a dining table with a height outside the typical range of 28-30 inches?",
    "Is there a dining table in the image that is not designed for serving meals or seating multiple people?"
  ]
}
```
Generated VLM Reasoning Questions {'yes_questions': ['Does the image contain a mammal?', 'Is there an animal in the image that might live with humans?', 'Is there an object in the image that could have whiskers and paws?', 'Does the image contain something that could hunt?', 'Is there an object in the image that could be a pet?'], 'no_questions': ['Does the image contain a reptile?', 'Is there an object that could have scales instead of fur?', 'Is there something in the image that lays eggs underwater?', 'Is there a vehicle in the image that transports people?', 'Does the image show a cold-blooded organism?']}
âœ… Saved: dining table
